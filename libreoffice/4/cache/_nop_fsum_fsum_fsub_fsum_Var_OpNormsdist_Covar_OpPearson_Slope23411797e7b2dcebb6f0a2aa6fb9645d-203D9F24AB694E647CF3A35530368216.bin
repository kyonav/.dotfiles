//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-31916684
// Driver 390.157
// Based on LLVM 3.4svn
//

.version 6.1
.target sm_21, texmode_independent
.address_size 64

	// .globl	DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope

.entry DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope(
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_0,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_1,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_2,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_3,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_4,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_5,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_6,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_7,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_8,
	.param .u64 .ptr .global .align 8 DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_9
)
{
	.reg .pred 	%p<383>;
	.reg .f32 	%f<9>;
	.reg .b32 	%r<273>;
	.reg .f64 	%fd<1582>;
	.reg .b64 	%rd<73>;


	ld.param.u64 	%rd4, [DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_1];
	ld.param.u64 	%rd5, [DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_2];
	ld.param.u64 	%rd6, [DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_3];
	ld.param.u64 	%rd7, [DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_4];
	ld.param.u64 	%rd8, [DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_5];
	ld.param.u64 	%rd9, [DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_6];
	ld.param.u64 	%rd10, [DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_7];
	ld.param.u64 	%rd11, [DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_8];
	ld.param.u64 	%rd12, [DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_9];
	mov.b32	%r106, %envreg3;
	mov.u32 	%r107, %ctaid.x;
	mov.u32 	%r108, %ntid.x;
	mad.lo.s32 	%r1, %r107, %r108, %r106;
	mov.u32 	%r2, %tid.x;
	add.s32 	%r3, %r1, %r2;
	mov.f64 	%fd1496, 0d0000000000000000;
	setp.gt.s32	%p1, %r3, 5;
	mov.f64 	%fd1495, %fd1496;
	mov.f64 	%fd1494, %fd1496;
	@%p1 bra 	BB0_6;

	add.s32 	%r242, %r1, %r2;
	mov.f64 	%fd1496, 0d0000000000000000;
	mov.u32 	%r241, 1;
	mov.f64 	%fd1495, %fd1496;
	mov.f64 	%fd1494, %fd1496;

BB0_2:
	mul.wide.s32 	%rd13, %r242, 8;
	add.s64 	%rd14, %rd11, %rd13;
	add.s64 	%rd15, %rd12, %rd13;
	ld.global.f64 	%fd4, [%rd15];
	ld.global.f64 	%fd5, [%rd14];
	abs.f64 	%fd279, %fd5;
	setp.gtu.f64	%p2, %fd279, 0d7FF0000000000000;
	@%p2 bra 	BB0_5;

	abs.f64 	%fd280, %fd4;
	setp.gtu.f64	%p3, %fd280, 0d7FF0000000000000;
	@%p3 bra 	BB0_5;

	add.f64 	%fd1495, %fd1495, %fd4;
	add.f64 	%fd1494, %fd1494, %fd5;
	add.f64 	%fd1496, %fd1496, 0d3FF0000000000000;

BB0_5:
	add.s32 	%r242, %r242, 1;
	setp.lt.s32	%p4, %r242, 6;
	setp.lt.s32	%p5, %r241, 2;
	and.pred  	%p6, %p4, %p5;
	add.s32 	%r241, %r241, 1;
	@%p6 bra 	BB0_2;

BB0_6:
	setp.lt.f64	%p7, %fd1496, 0d3FF0000000000000;
	mov.f64 	%fd1506, 0d7FF8000000000207;
	@%p7 bra 	BB0_15;

	div.rn.f64 	%fd15, %fd1495, %fd1496;
	div.rn.f64 	%fd16, %fd1494, %fd1496;
	mov.f64 	%fd1503, 0d0000000000000000;
	mov.f64 	%fd1502, %fd1503;
	@%p1 bra 	BB0_13;

	mov.f64 	%fd1503, 0d0000000000000000;
	mov.u32 	%r243, 1;
	mov.u32 	%r244, %r3;
	mov.f64 	%fd1502, %fd1503;

BB0_9:
	mul.wide.s32 	%rd16, %r244, 8;
	add.s64 	%rd17, %rd11, %rd16;
	add.s64 	%rd18, %rd12, %rd16;
	ld.global.f64 	%fd19, [%rd18];
	ld.global.f64 	%fd20, [%rd17];
	abs.f64 	%fd286, %fd20;
	setp.gtu.f64	%p9, %fd286, 0d7FF0000000000000;
	@%p9 bra 	BB0_12;

	abs.f64 	%fd287, %fd19;
	setp.gtu.f64	%p10, %fd287, 0d7FF0000000000000;
	@%p10 bra 	BB0_12;

	sub.f64 	%fd288, %fd19, %fd15;
	sub.f64 	%fd289, %fd20, %fd16;
	fma.rn.f64 	%fd1503, %fd289, %fd288, %fd1503;
	fma.rn.f64 	%fd1502, %fd288, %fd288, %fd1502;

BB0_12:
	add.s32 	%r244, %r244, 1;
	setp.lt.s32	%p11, %r244, 6;
	setp.lt.s32	%p12, %r243, 2;
	and.pred  	%p13, %p11, %p12;
	add.s32 	%r243, %r243, 1;
	@%p13 bra 	BB0_9;

BB0_13:
	setp.eq.f64	%p14, %fd1502, 0d0000000000000000;
	mov.f64 	%fd1506, 0d7FF8000000000214;
	@%p14 bra 	BB0_15;

	div.rn.f64 	%fd1506, %fd1503, %fd1502;

BB0_15:
	add.f64 	%fd29, %fd1506, 0d0000000000000000;
	mov.f64 	%fd1512, 0d0000000000000000;
	mov.f64 	%fd1511, %fd1512;
	mov.f64 	%fd1510, %fd1512;
	@%p1 bra 	BB0_21;

	add.s32 	%r246, %r1, %r2;
	mov.f64 	%fd1512, 0d0000000000000000;
	mov.u32 	%r245, 1;
	mov.f64 	%fd1511, %fd1512;
	mov.f64 	%fd1510, %fd1512;

BB0_17:
	mul.wide.s32 	%rd19, %r246, 8;
	add.s64 	%rd20, %rd9, %rd19;
	add.s64 	%rd21, %rd10, %rd19;
	ld.global.f64 	%fd33, [%rd21];
	ld.global.f64 	%fd34, [%rd20];
	abs.f64 	%fd297, %fd34;
	setp.gtu.f64	%p16, %fd297, 0d7FF0000000000000;
	@%p16 bra 	BB0_20;

	abs.f64 	%fd298, %fd33;
	setp.gtu.f64	%p17, %fd298, 0d7FF0000000000000;
	@%p17 bra 	BB0_20;

	add.f64 	%fd1511, %fd1511, %fd33;
	add.f64 	%fd1510, %fd1510, %fd34;
	add.f64 	%fd1512, %fd1512, 0d3FF0000000000000;

BB0_20:
	add.s32 	%r246, %r246, 1;
	setp.lt.s32	%p18, %r246, 6;
	setp.lt.s32	%p19, %r245, 2;
	and.pred  	%p20, %p18, %p19;
	add.s32 	%r245, %r245, 1;
	@%p20 bra 	BB0_17;

BB0_21:
	setp.lt.f64	%p21, %fd1512, 0d3FF0000000000000;
	mov.f64 	%fd1525, 0d7FF8000000000207;
	@%p21 bra 	BB0_30;

	div.rn.f64 	%fd44, %fd1511, %fd1512;
	div.rn.f64 	%fd45, %fd1510, %fd1512;
	mov.f64 	%fd1521, 0d0000000000000000;
	mov.f64 	%fd1520, %fd1521;
	mov.f64 	%fd1519, %fd1521;
	@%p1 bra 	BB0_28;

	add.s32 	%r248, %r1, %r2;
	mov.f64 	%fd1521, 0d0000000000000000;
	mov.u32 	%r247, 1;
	mov.f64 	%fd1520, %fd1521;
	mov.f64 	%fd1519, %fd1521;

BB0_24:
	mul.wide.s32 	%rd22, %r248, 8;
	add.s64 	%rd23, %rd9, %rd22;
	add.s64 	%rd24, %rd10, %rd22;
	ld.global.f64 	%fd49, [%rd24];
	ld.global.f64 	%fd50, [%rd23];
	abs.f64 	%fd306, %fd50;
	setp.gtu.f64	%p23, %fd306, 0d7FF0000000000000;
	@%p23 bra 	BB0_27;

	abs.f64 	%fd307, %fd49;
	setp.gtu.f64	%p24, %fd307, 0d7FF0000000000000;
	@%p24 bra 	BB0_27;

	sub.f64 	%fd308, %fd49, %fd44;
	sub.f64 	%fd309, %fd50, %fd45;
	fma.rn.f64 	%fd1521, %fd309, %fd308, %fd1521;
	fma.rn.f64 	%fd1520, %fd308, %fd308, %fd1520;
	fma.rn.f64 	%fd1519, %fd309, %fd309, %fd1519;

BB0_27:
	add.s32 	%r248, %r248, 1;
	setp.lt.s32	%p25, %r248, 6;
	setp.lt.s32	%p26, %r247, 2;
	and.pred  	%p27, %p25, %p26;
	add.s32 	%r247, %r247, 1;
	@%p27 bra 	BB0_24;

BB0_28:
	setp.eq.f64	%p28, %fd1519, 0d0000000000000000;
	setp.eq.f64	%p29, %fd1520, 0d0000000000000000;
	or.pred  	%p30, %p29, %p28;
	mov.f64 	%fd1525, 0d7FF8000000000214;
	@%p30 bra 	BB0_30;

	mul.f64 	%fd311, %fd1519, %fd1520;
	sqrt.rn.f64 	%fd312, %fd311;
	div.rn.f64 	%fd1525, %fd1521, %fd312;

BB0_30:
	add.f64 	%fd62, %fd1525, 0d0000000000000000;
	mov.f64 	%fd1531, 0d0000000000000000;
	mov.f64 	%fd1530, %fd1531;
	mov.f64 	%fd1529, %fd1531;
	@%p1 bra 	BB0_36;

	add.s32 	%r250, %r1, %r2;
	mov.f64 	%fd1531, 0d0000000000000000;
	mov.u32 	%r249, 1;
	mov.f64 	%fd1530, %fd1531;
	mov.f64 	%fd1529, %fd1531;

BB0_32:
	mul.wide.s32 	%rd25, %r250, 8;
	add.s64 	%rd26, %rd7, %rd25;
	add.s64 	%rd27, %rd8, %rd25;
	ld.global.f64 	%fd66, [%rd27];
	ld.global.f64 	%fd67, [%rd26];
	abs.f64 	%fd319, %fd67;
	setp.gtu.f64	%p32, %fd319, 0d7FF0000000000000;
	@%p32 bra 	BB0_35;

	abs.f64 	%fd320, %fd66;
	setp.gtu.f64	%p33, %fd320, 0d7FF0000000000000;
	@%p33 bra 	BB0_35;

	add.f64 	%fd1530, %fd1530, %fd67;
	add.f64 	%fd1529, %fd1529, %fd66;
	add.f64 	%fd1531, %fd1531, 0d3FF0000000000000;

BB0_35:
	add.s32 	%r250, %r250, 1;
	setp.lt.s32	%p34, %r250, 6;
	setp.lt.s32	%p35, %r249, 2;
	and.pred  	%p36, %p34, %p35;
	add.s32 	%r249, %r249, 1;
	@%p36 bra 	BB0_32;

BB0_36:
	setp.lt.f64	%p37, %fd1531, 0d3FF0000000000000;
	mov.f64 	%fd1538, 0d7FF8000000000207;
	@%p37 bra 	BB0_44;

	mov.f64 	%fd1536, 0d0000000000000000;
	@%p1 bra 	BB0_43;

	add.s32 	%r252, %r1, %r2;
	div.rn.f64 	%fd77, %fd1529, %fd1531;
	div.rn.f64 	%fd78, %fd1530, %fd1531;
	mov.f64 	%fd1536, 0d0000000000000000;
	mov.u32 	%r251, 1;

BB0_39:
	mul.wide.s32 	%rd28, %r252, 8;
	add.s64 	%rd29, %rd7, %rd28;
	add.s64 	%rd30, %rd8, %rd28;
	ld.global.f64 	%fd80, [%rd30];
	ld.global.f64 	%fd81, [%rd29];
	abs.f64 	%fd324, %fd81;
	setp.gtu.f64	%p39, %fd324, 0d7FF0000000000000;
	@%p39 bra 	BB0_42;

	abs.f64 	%fd325, %fd80;
	setp.gtu.f64	%p40, %fd325, 0d7FF0000000000000;
	@%p40 bra 	BB0_42;

	sub.f64 	%fd326, %fd81, %fd78;
	sub.f64 	%fd327, %fd80, %fd77;
	fma.rn.f64 	%fd1536, %fd326, %fd327, %fd1536;

BB0_42:
	add.s32 	%r252, %r252, 1;
	setp.lt.s32	%p41, %r252, 6;
	setp.lt.s32	%p42, %r251, 2;
	and.pred  	%p43, %p41, %p42;
	add.s32 	%r251, %r251, 1;
	@%p43 bra 	BB0_39;

BB0_43:
	div.rn.f64 	%fd1538, %fd1536, %fd1531;

BB0_44:
	mov.f64 	%fd1539, 0d7FFFFFFFE0000000;
	setp.gt.s32	%p44, %r3, 4;
	@%p44 bra 	BB0_46;

	mul.wide.s32 	%rd31, %r3, 8;
	add.s64 	%rd32, %rd6, %rd31;
	ld.global.f64 	%fd1539, [%rd32];

BB0_46:
	abs.f64 	%fd330, %fd1539;
	setp.gtu.f64	%p45, %fd330, 0d7FF0000000000000;
	mul.f64 	%fd331, %fd1539, 0dBFE6A09E667F3BCC;
	selp.f64	%fd329, 0d8000000000000000, %fd331, %p45;
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r120}, %fd329; 
	}
	// inline asm
	setp.lt.s32	%p46, %r120, 1072168960;
	@%p46 bra 	BB0_53;
	bra.uni 	BB0_47;

BB0_53:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd329;
	}
	and.b32  	%r36, %r35, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r37, %temp}, %fd329;
	}
	setp.lt.u32	%p52, %r36, 1072693248;
	@%p52 bra 	BB0_59;
	bra.uni 	BB0_54;

BB0_59:
	mul.f64 	%fd587, %fd329, %fd329;
	mov.f64 	%fd588, 0d3E4D5F4BB7A316F6;
	mov.f64 	%fd589, 0dBE0A83AA3B08FBC2;
	fma.rn.f64 	%fd590, %fd589, %fd587, %fd588;
	mov.f64 	%fd591, 0dBE85BDCE301B3CDF;
	fma.rn.f64 	%fd592, %fd590, %fd587, %fd591;
	mov.f64 	%fd593, 0d3EBB978FADB81BC9;
	fma.rn.f64 	%fd594, %fd592, %fd587, %fd593;
	mov.f64 	%fd595, 0dBEEF4C99D6AE5FB8;
	fma.rn.f64 	%fd596, %fd594, %fd587, %fd595;
	mov.f64 	%fd597, 0d3F1F9A2AF549012E;
	fma.rn.f64 	%fd598, %fd596, %fd587, %fd597;
	mov.f64 	%fd599, 0dBF4C02DAFC636A47;
	fma.rn.f64 	%fd600, %fd598, %fd587, %fd599;
	mov.f64 	%fd601, 0d3F7565BCCF619AC0;
	fma.rn.f64 	%fd602, %fd600, %fd587, %fd601;
	mov.f64 	%fd603, 0dBF9B82CE311E321A;
	fma.rn.f64 	%fd604, %fd602, %fd587, %fd603;
	mov.f64 	%fd605, 0d3FBCE2F21A04075C;
	fma.rn.f64 	%fd606, %fd604, %fd587, %fd605;
	mov.f64 	%fd607, 0dBFD812746B0379B4;
	fma.rn.f64 	%fd608, %fd606, %fd587, %fd607;
	mov.f64 	%fd609, 0d3FF20DD750429B6D;
	fma.rn.f64 	%fd610, %fd608, %fd587, %fd609;
	mul.f64 	%fd1541, %fd329, %fd610;
	bra.uni 	BB0_60;

BB0_47:
	setp.gt.f64	%p47, %fd329, 0d403B4CCCCCCCCCCD;
	mov.f64 	%fd1542, 0d0000000000000000;
	@%p47 bra 	BB0_61;

	mul.rn.f64 	%fd337, %fd329, %fd329;
	neg.f64 	%fd336, %fd337;
	// inline asm
	fma.rn.f64 	%fd333, %fd329, %fd329, %fd336;
	// inline asm
	mov.f64 	%fd338, 0d3FF71547652B82FE;
	mul.rn.f64 	%fd1540, %fd336, %fd338;
	abs.f64 	%fd93, %fd1540;
	setp.ge.f64	%p48, %fd93, 0d4330000000000000;
	@%p48 bra 	BB0_50;

	add.f64 	%fd339, %fd93, 0d3FE0000000000000;
	cvt.rzi.f64.f64	%fd340, %fd339;
	setp.lt.f64	%p49, %fd93, 0d3FE0000000000000;
	selp.f64	%fd341, 0d0000000000000000, %fd340, %p49;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r121, %temp}, %fd341;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r122}, %fd341;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r123}, %fd1540;
	}
	and.b32  	%r124, %r123, -2147483648;
	or.b32  	%r125, %r122, %r124;
	mov.b64 	%fd1540, {%r121, %r125};

BB0_50:
	mov.f64 	%fd344, 0dBFE62E42FEFA39EF;
	// inline asm
	fma.rn.f64 	%fd342, %fd1540, %fd344, %fd336;
	// inline asm
	mov.f64 	%fd348, 0dBC7ABC9E3B39803F;
	// inline asm
	fma.rn.f64 	%fd346, %fd1540, %fd348, %fd342;
	// inline asm
	cvt.rzi.s32.f64	%r128, %fd1540;
	setp.lt.s32	%p50, %r128, -1020;
	add.s32 	%r129, %r128, 55;
	selp.f64	%fd403, 0d3C90000000000000, 0d4000000000000000, %p50;
	selp.b32	%r130, %r129, %r128, %p50;
	mov.f64 	%fd351, 0d3E21F07FCCF58BAD;
	mov.f64 	%fd353, 0d3E5AFD81DA6C3BAF;
	// inline asm
	fma.rn.f64 	%fd350, %fd351, %fd346, %fd353;
	// inline asm
	mov.f64 	%fd357, 0d3E927E55F60F80E6;
	// inline asm
	fma.rn.f64 	%fd354, %fd350, %fd346, %fd357;
	// inline asm
	mov.f64 	%fd361, 0d3EC71DDA8F02D666;
	// inline asm
	fma.rn.f64 	%fd358, %fd354, %fd346, %fd361;
	// inline asm
	mov.f64 	%fd365, 0d3EFA01A013B894E0;
	// inline asm
	fma.rn.f64 	%fd362, %fd358, %fd346, %fd365;
	// inline asm
	mov.f64 	%fd369, 0d3F2A01A01D3AF788;
	// inline asm
	fma.rn.f64 	%fd366, %fd362, %fd346, %fd369;
	// inline asm
	mov.f64 	%fd373, 0d3F56C16C16C3A1EC;
	// inline asm
	fma.rn.f64 	%fd370, %fd366, %fd346, %fd373;
	// inline asm
	mov.f64 	%fd377, 0d3F81111111109161;
	// inline asm
	fma.rn.f64 	%fd374, %fd370, %fd346, %fd377;
	// inline asm
	mov.f64 	%fd381, 0d3FA55555555554C1;
	// inline asm
	fma.rn.f64 	%fd378, %fd374, %fd346, %fd381;
	// inline asm
	mov.f64 	%fd385, 0d3FC555555555556F;
	// inline asm
	fma.rn.f64 	%fd382, %fd378, %fd346, %fd385;
	// inline asm
	mov.f64 	%fd389, 0d3FE0000000000000;
	// inline asm
	fma.rn.f64 	%fd386, %fd382, %fd346, %fd389;
	// inline asm
	mul.rn.f64 	%fd391, %fd386, %fd346;
	// inline asm
	fma.rn.f64 	%fd390, %fd391, %fd346, %fd346;
	// inline asm
	add.s32 	%r131, %r130, 1022;
	shl.b32 	%r127, %r131, 20;
	mov.u32 	%r126, 0;
	// inline asm
	mov.b64 	%fd394, {%r126, %r127};
	// inline asm
	// inline asm
	fma.rn.f64 	%fd395, %fd390, %fd394, %fd394;
	// inline asm
	mul.rn.f64 	%fd402, %fd395, %fd403;
	neg.f64 	%fd401, %fd402;
	// inline asm
	fma.rn.f64 	%fd399, %fd333, %fd401, %fd402;
	// inline asm
	setp.lt.s32	%p51, %r120, 1075052544;
	@%p51 bra 	BB0_52;
	bra.uni 	BB0_51;

BB0_52:
	mov.f64 	%fd451, 0d3FE20DD7452FBC22;
	mov.f64 	%fd453, 0d401FD453E105E9A2;
	// inline asm
	fma.rn.f64 	%fd450, %fd451, %fd329, %fd453;
	// inline asm
	mov.f64 	%fd457, 0d404B26245B951FB4;
	// inline asm
	fma.rn.f64 	%fd454, %fd450, %fd329, %fd457;
	// inline asm
	mov.f64 	%fd461, 0d406C7835DC0F1F49;
	// inline asm
	fma.rn.f64 	%fd458, %fd454, %fd329, %fd461;
	// inline asm
	mov.f64 	%fd465, 0d4083AFA471E5C766;
	// inline asm
	fma.rn.f64 	%fd462, %fd458, %fd329, %fd465;
	// inline asm
	mov.f64 	%fd469, 0d4091FB514824F49F;
	// inline asm
	fma.rn.f64 	%fd466, %fd462, %fd329, %fd469;
	// inline asm
	mov.f64 	%fd473, 0d409450DDEE8272BB;
	// inline asm
	fma.rn.f64 	%fd470, %fd466, %fd329, %fd473;
	// inline asm
	mov.f64 	%fd477, 0d4086B952E4ECBC50;
	// inline asm
	fma.rn.f64 	%fd474, %fd470, %fd329, %fd477;
	// inline asm
	add.f64 	%fd479, %fd329, 0d402C35442E99E667;
	mov.f64 	%fd481, 0d40582F68071A079D;
	// inline asm
	fma.rn.f64 	%fd478, %fd479, %fd329, %fd481;
	// inline asm
	mov.f64 	%fd485, 0d4079ABD39A029DAA;
	// inline asm
	fma.rn.f64 	%fd482, %fd478, %fd329, %fd485;
	// inline asm
	mov.f64 	%fd489, 0d409230CA327093FD;
	// inline asm
	fma.rn.f64 	%fd486, %fd482, %fd329, %fd489;
	// inline asm
	mov.f64 	%fd493, 0d40A174FAB33B54A7;
	// inline asm
	fma.rn.f64 	%fd490, %fd486, %fd329, %fd493;
	// inline asm
	mov.f64 	%fd497, 0d40A601508230F980;
	// inline asm
	fma.rn.f64 	%fd494, %fd490, %fd329, %fd497;
	// inline asm
	mov.f64 	%fd501, 0d40A091785EC9331E;
	// inline asm
	fma.rn.f64 	%fd498, %fd494, %fd329, %fd501;
	// inline asm
	mov.f64 	%fd505, 0d4086B952E52F3622;
	// inline asm
	fma.rn.f64 	%fd502, %fd498, %fd329, %fd505;
	// inline asm
	div.rn.f64 	%fd506, %fd474, %fd502;
	mul.rn.f64 	%fd1542, %fd506, %fd399;
	bra.uni 	BB0_61;

BB0_54:
	setp.lt.u32	%p53, %r36, 2146435072;
	@%p53 bra 	BB0_58;
	bra.uni 	BB0_55;

BB0_58:
	mov.b64 	%fd508, {%r37, %r36};
	mov.f64 	%fd509, 0dBCF1384CE38C616A;
	mov.f64 	%fd510, 0d3C8B9C2B870030E8;
	fma.rn.f64 	%fd511, %fd510, %fd508, %fd509;
	mov.f64 	%fd512, 0d3D4458AE9746C2FD;
	fma.rn.f64 	%fd513, %fd511, %fd508, %fd512;
	mov.f64 	%fd514, 0dBD8E4A44D4F1AB56;
	fma.rn.f64 	%fd515, %fd513, %fd508, %fd514;
	mov.f64 	%fd516, 0d3DCFDF15265C58EE;
	fma.rn.f64 	%fd517, %fd515, %fd508, %fd516;
	mov.f64 	%fd518, 0dBE0933832F358D51;
	fma.rn.f64 	%fd519, %fd517, %fd508, %fd518;
	mov.f64 	%fd520, 0d3E3F136D3F719446;
	fma.rn.f64 	%fd521, %fd519, %fd508, %fd520;
	mov.f64 	%fd522, 0dBE6E94C2FE151B3B;
	fma.rn.f64 	%fd523, %fd521, %fd508, %fd522;
	mov.f64 	%fd524, 0d3E985A70310EE0A8;
	fma.rn.f64 	%fd525, %fd523, %fd508, %fd524;
	mov.f64 	%fd526, 0dBEBF944DA1520B74;
	fma.rn.f64 	%fd527, %fd525, %fd508, %fd526;
	mov.f64 	%fd528, 0d3EE09F503825C543;
	fma.rn.f64 	%fd529, %fd527, %fd508, %fd528;
	mov.f64 	%fd530, 0dBEFBEEFE9F949E59;
	fma.rn.f64 	%fd531, %fd529, %fd508, %fd530;
	mov.f64 	%fd532, 0d3F11D785C6E28857;
	fma.rn.f64 	%fd533, %fd531, %fd508, %fd532;
	mov.f64 	%fd534, 0dBF1D866B223048C7;
	fma.rn.f64 	%fd535, %fd533, %fd508, %fd534;
	mov.f64 	%fd536, 0d3EF258F0847E8908;
	fma.rn.f64 	%fd537, %fd535, %fd508, %fd536;
	mov.f64 	%fd538, 0d3F429CFC58DBB776;
	fma.rn.f64 	%fd539, %fd537, %fd508, %fd538;
	mov.f64 	%fd540, 0dBF5BE16D3F71F3C5;
	fma.rn.f64 	%fd541, %fd539, %fd508, %fd540;
	mov.f64 	%fd542, 0d3F2E8BDA60326B1A;
	fma.rn.f64 	%fd543, %fd541, %fd508, %fd542;
	mov.f64 	%fd544, 0d3F938FB20B0988A6;
	fma.rn.f64 	%fd545, %fd543, %fd508, %fd544;
	mov.f64 	%fd546, 0dBFBA4E3A80F64E33;
	fma.rn.f64 	%fd547, %fd545, %fd508, %fd546;
	mov.f64 	%fd548, 0dBFE45F3E88093928;
	fma.rn.f64 	%fd549, %fd547, %fd508, %fd548;
	mov.f64 	%fd550, 0dBFF20DD599CAEEA0;
	fma.rn.f64 	%fd551, %fd549, %fd508, %fd550;
	mov.f64 	%fd552, 0dBE883BE1E31CE133;
	fma.rn.f64 	%fd553, %fd551, %fd508, %fd552;
	mov.f64 	%fd554, 0d3FF71547652B82FE;
	mul.rn.f64 	%fd555, %fd553, %fd554;
	mov.f64 	%fd556, 0d4338000000000000;
	add.rn.f64 	%fd557, %fd555, %fd556;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r136, %temp}, %fd557;
	}
	mov.f64 	%fd558, 0dC338000000000000;
	add.rn.f64 	%fd559, %fd557, %fd558;
	mov.f64 	%fd560, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd561, %fd559, %fd560, %fd553;
	mov.f64 	%fd562, 0d3E928AF3FCA213EA;
	mov.f64 	%fd563, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd564, %fd563, %fd561, %fd562;
	mov.f64 	%fd565, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd566, %fd564, %fd561, %fd565;
	mov.f64 	%fd567, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd568, %fd566, %fd561, %fd567;
	mov.f64 	%fd569, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd570, %fd568, %fd561, %fd569;
	mov.f64 	%fd571, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd572, %fd570, %fd561, %fd571;
	mov.f64 	%fd573, 0d3F81111111122322;
	fma.rn.f64 	%fd574, %fd572, %fd561, %fd573;
	mov.f64 	%fd575, 0d3FA55555555502A1;
	fma.rn.f64 	%fd576, %fd574, %fd561, %fd575;
	mov.f64 	%fd577, 0d3FC5555555555511;
	fma.rn.f64 	%fd578, %fd576, %fd561, %fd577;
	mov.f64 	%fd579, 0d3FE000000000000B;
	fma.rn.f64 	%fd580, %fd578, %fd561, %fd579;
	mov.f64 	%fd581, 0d3FF0000000000000;
	fma.rn.f64 	%fd582, %fd580, %fd561, %fd581;
	fma.rn.f64 	%fd583, %fd582, %fd561, %fd581;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r137}, %fd583;
	}
	shl.b32 	%r138, %r136, 20;
	add.s32 	%r139, %r137, %r138;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r140, %temp}, %fd583;
	}
	mov.b64 	%fd584, {%r140, %r139};
	sub.f64 	%fd585, %fd581, %fd584;
	setp.gt.u32	%p57, %r36, 1075294207;
	selp.f64	%fd586, 0d3FF0000000000000, %fd585, %p57;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r141, %temp}, %fd586;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r142}, %fd586;
	}
	and.b32  	%r143, %r35, -2147483648;
	or.b32  	%r144, %r142, %r143;
	mov.b64 	%fd1541, {%r141, %r144};
	bra.uni 	BB0_60;

BB0_51:
	rcp.rn.f64 	%fd448, %fd329;
	mul.rn.f64 	%fd446, %fd448, %fd448;
	mov.f64 	%fd405, 0dC1186DF84479631D;
	mov.f64 	%fd407, 0d41019A6E9A7FFBB8;
	// inline asm
	fma.rn.f64 	%fd404, %fd405, %fd446, %fd407;
	// inline asm
	mov.f64 	%fd411, 0dC0DB040BE3D5CA18;
	// inline asm
	fma.rn.f64 	%fd408, %fd404, %fd446, %fd411;
	// inline asm
	mov.f64 	%fd415, 0d40B012760EE009A0;
	// inline asm
	fma.rn.f64 	%fd412, %fd408, %fd446, %fd415;
	// inline asm
	mov.f64 	%fd419, 0dC082587AE4008D0E;
	// inline asm
	fma.rn.f64 	%fd416, %fd412, %fd446, %fd419;
	// inline asm
	mov.f64 	%fd423, 0d4056DF5D938ACAFE;
	// inline asm
	fma.rn.f64 	%fd420, %fd416, %fd446, %fd423;
	// inline asm
	mov.f64 	%fd427, 0dC030A8D46D765681;
	// inline asm
	fma.rn.f64 	%fd424, %fd420, %fd446, %fd427;
	// inline asm
	mov.f64 	%fd431, 0d400D9EAE0C665C75;
	// inline asm
	fma.rn.f64 	%fd428, %fd424, %fd446, %fd431;
	// inline asm
	mov.f64 	%fd435, 0dBFF0ECF9C8880942;
	// inline asm
	fma.rn.f64 	%fd432, %fd428, %fd446, %fd435;
	// inline asm
	mov.f64 	%fd439, 0d3FDB14C2F82A33F7;
	// inline asm
	fma.rn.f64 	%fd436, %fd432, %fd446, %fd439;
	// inline asm
	mov.f64 	%fd443, 0dBFD20DD75042844F;
	// inline asm
	fma.rn.f64 	%fd440, %fd436, %fd446, %fd443;
	// inline asm
	mov.f64 	%fd447, 0d3FE20DD750429B6B;
	// inline asm
	fma.rn.f64 	%fd444, %fd440, %fd446, %fd447;
	// inline asm
	mul.rn.f64 	%fd449, %fd444, %fd448;
	mul.rn.f64 	%fd1542, %fd449, %fd399;
	bra.uni 	BB0_61;

BB0_55:
	setp.eq.s32	%p54, %r36, 2146435072;
	setp.eq.s32	%p55, %r37, 0;
	and.pred  	%p56, %p54, %p55;
	@%p56 bra 	BB0_57;
	bra.uni 	BB0_56;

BB0_57:
	mov.f64 	%fd507, 0d3FF0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r132, %temp}, %fd507;
	}
	and.b32  	%r133, %r35, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r134}, %fd507;
	}
	or.b32  	%r135, %r134, %r133;
	mov.b64 	%fd1541, {%r132, %r135};
	bra.uni 	BB0_60;

BB0_56:
	add.f64 	%fd1541, %fd329, %fd329;

BB0_60:
	mov.f64 	%fd611, 0d3FF0000000000000;
	sub.f64 	%fd1542, %fd611, %fd1541;

BB0_61:
	fma.rn.f64 	%fd106, %fd1542, 0d3FE0000000000000, 0d0000000000000000;
	mul.wide.s32 	%rd33, %r3, 8;
	add.s64 	%rd1, %rd4, %rd33;
	mov.f64 	%fd1543, 0d0000000000000000;
	mov.f64 	%fd1544, %fd1543;
	@%p44 bra 	BB0_63;

	ld.global.f64 	%fd614, [%rd1];
	abs.f64 	%fd615, %fd614;
	setp.gtu.f64	%p59, %fd615, 0d7FF0000000000000;
	add.f64 	%fd616, %fd614, 0d0000000000000000;
	selp.f64	%fd1543, 0d0000000000000000, %fd616, %p59;
	selp.f64	%fd1544, 0d0000000000000000, 0d3FF0000000000000, %p59;

BB0_63:
	add.s64 	%rd2, %rd5, %rd33;
	@%p44 bra 	BB0_65;

	ld.global.f64 	%fd617, [%rd2];
	abs.f64 	%fd618, %fd617;
	setp.gtu.f64	%p61, %fd618, 0d7FF0000000000000;
	add.f64 	%fd619, %fd1543, %fd617;
	selp.f64	%fd1543, %fd1543, %fd619, %p61;
	add.f64 	%fd620, %fd1544, 0d3FF0000000000000;
	selp.f64	%fd1544, %fd1544, %fd620, %p61;

BB0_65:
	setp.eq.f64	%p62, %fd1544, 0d0000000000000000;
	mov.f64 	%fd1577, 0d7FF8000000000214;
	@%p62 bra 	BB0_228;

	div.rn.f64 	%fd115, %fd1543, %fd1544;
	mov.f64 	%fd1561, 0d0000000000000000;
	@%p44 bra 	BB0_146;

	ld.global.f64 	%fd116, [%rd1];
	abs.f64 	%fd117, %fd116;
	setp.gtu.f64	%p64, %fd117, 0d7FF0000000000000;
	@%p64 bra 	BB0_146;

	setp.lt.f64	%p65, %fd116, 0d0000000000000000;
	setp.lt.f64	%p66, %fd115, 0d0000000000000000;
	and.pred  	%p67, %p65, %p66;
	@%p67 bra 	BB0_70;

	setp.gt.f64	%p68, %fd116, 0d0000000000000000;
	setp.gt.f64	%p69, %fd115, 0d0000000000000000;
	and.pred  	%p70, %p68, %p69;
	@!%p70 bra 	BB0_78;
	bra.uni 	BB0_70;

BB0_70:
	setp.eq.f64	%p71, %fd116, %fd115;
	mov.f64 	%fd121, 0d0000000000000000;
	@%p71 bra 	BB0_79;

	setp.eq.f64	%p72, %fd116, 0d0000000000000000;
	setp.eq.f64	%p73, %fd115, 0d0000000000000000;
	or.pred  	%p74, %p72, %p73;
	@%p74 bra 	BB0_78;

	sub.f64 	%fd625, %fd116, %fd115;
	abs.f64 	%fd118, %fd625;
	abs.f64 	%fd626, %fd118;
	setp.geu.f64	%p75, %fd626, 0d7FF0000000000000;
	mul.f64 	%fd627, %fd117, 0d3D30000000000000;
	setp.gt.f64	%p76, %fd118, %fd627;
	or.pred  	%p77, %p75, %p76;
	@%p77 bra 	BB0_78;

	abs.f64 	%fd119, %fd115;
	mul.f64 	%fd628, %fd119, 0d3D30000000000000;
	setp.gt.f64	%p78, %fd118, %fd628;
	@%p78 bra 	BB0_78;

	setp.gtu.f64	%p79, %fd118, 0d433FFFFFFFFFFFFF;
	@%p79 bra 	BB0_277;

	cvt.rzi.s64.f64	%rd35, %fd118;
	setp.gt.s64	%p80, %rd35, 9007199254740991;
	cvt.rn.f64.s64	%fd629, %rd35;
	setp.ne.f64	%p81, %fd629, %fd118;
	or.pred  	%p82, %p80, %p81;
	setp.gtu.f64	%p83, %fd117, 0d433FFFFFFFFFFFFF;
	or.pred  	%p84, %p82, %p83;
	@%p84 bra 	BB0_277;

	cvt.rzi.s64.f64	%rd36, %fd117;
	setp.gt.s64	%p85, %rd36, 9007199254740991;
	cvt.rn.f64.s64	%fd630, %rd36;
	setp.ne.f64	%p86, %fd630, %fd117;
	or.pred  	%p87, %p85, %p86;
	setp.gtu.f64	%p88, %fd119, 0d433FFFFFFFFFFFFF;
	or.pred  	%p89, %p87, %p88;
	@%p89 bra 	BB0_277;
	bra.uni 	BB0_77;

BB0_277:
	mul.f64 	%fd636, %fd117, 0d3CF0000000000000;
	setp.geu.f64	%p97, %fd118, %fd636;
	mul.f64 	%fd637, %fd119, 0d3CF0000000000000;
	setp.geu.f64	%p98, %fd118, %fd637;
	or.pred  	%p99, %p97, %p98;
	@!%p99 bra 	BB0_79;
	bra.uni 	BB0_78;

BB0_77:
	cvt.rzi.s64.f64	%rd37, %fd119;
	setp.lt.s64	%p90, %rd37, 9007199254740992;
	cvt.rn.f64.s64	%fd632, %rd37;
	setp.equ.f64	%p91, %fd632, %fd119;
	and.pred  	%p92, %p90, %p91;
	mul.f64 	%fd633, %fd117, 0d3CF0000000000000;
	setp.geu.f64	%p93, %fd118, %fd633;
	or.pred  	%p94, %p92, %p93;
	mul.f64 	%fd634, %fd119, 0d3CF0000000000000;
	setp.geu.f64	%p95, %fd118, %fd634;
	or.pred  	%p96, %p95, %p94;
	@%p96 bra 	BB0_78;
	bra.uni 	BB0_79;

BB0_78:
	sub.f64 	%fd121, %fd116, %fd115;

BB0_79:
	abs.f64 	%fd122, %fd121;
	setp.gtu.f64	%p100, %fd122, 0d7FF0000000000000;
	mov.f64 	%fd1560, 0dFFF8000000000000;
	@%p100 bra 	BB0_145;

	setp.eq.f64	%p101, %fd121, 0d0000000000000000;
	mov.f64 	%fd1560, 0d0000000000000000;
	@%p101 bra 	BB0_145;

	setp.eq.f64	%p102, %fd122, 0d3FF0000000000000;
	mov.f64 	%fd1552, 0d3FF0000000000000;
	@%p102 bra 	BB0_107;

	abs.f64 	%fd123, %fd122;
	setp.gtu.f64	%p103, %fd123, 0d7FF0000000000000;
	@%p103 bra 	BB0_106;
	bra.uni 	BB0_83;

BB0_106:
	add.f64 	%fd1552, %fd122, 0d4000000000000000;
	bra.uni 	BB0_107;

BB0_83:
	setp.eq.f64	%p104, %fd122, 0d7FF0000000000000;
	@%p104 bra 	BB0_105;
	bra.uni 	BB0_84;

BB0_105:
	mov.f64 	%fd825, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r165}, %fd825;
	}
	setp.gt.s32	%p121, %r165, -1;
	selp.f64	%fd1552, 0d7FF0000000000000, 0d0000000000000000, %p121;
	bra.uni 	BB0_107;

BB0_84:
	mov.f64 	%fd641, 0d4000000000000000;
	mov.f64 	%fd642, 0d3FE0000000000000;
	mul.rn.f64 	%fd643, %fd642, %fd641;
	cvt.rzi.f64.f64	%fd644, %fd643;
	mul.rn.f64 	%fd645, %fd641, %fd644;
	sub.f64 	%fd646, %fd641, %fd645;
	abs.f64 	%fd124, %fd646;
	setp.eq.f64	%p105, %fd122, 0d0000000000000000;
	@%p105 bra 	BB0_104;
	bra.uni 	BB0_85;

BB0_104:
	setp.eq.f64	%p120, %fd124, 0d3FF0000000000000;
	selp.f64	%fd1552, %fd122, 0d0000000000000000, %p120;
	bra.uni 	BB0_107;

BB0_85:
	setp.eq.f64	%p106, %fd122, 0dFFF0000000000000;
	@%p106 bra 	BB0_102;
	bra.uni 	BB0_86;

BB0_102:
	neg.f64 	%fd1552, %fd122;
	setp.neu.f64	%p119, %fd124, 0d3FF0000000000000;
	@%p119 bra 	BB0_107;

	mov.b64 	 %rd40, %fd1552;
	xor.b64  	%rd41, %rd40, -9223372036854775808;
	mov.b64 	 %fd1552, %rd41;
	bra.uni 	BB0_107;

BB0_86:
	setp.geu.f64	%p107, %fd122, 0d0000000000000000;
	@%p107 bra 	BB0_88;

	cvt.rzi.f64.f64	%fd649, %fd641;
	setp.neu.f64	%p108, %fd649, 0d4000000000000000;
	mov.f64 	%fd1552, 0dFFF8000000000000;
	@%p108 bra 	BB0_107;

BB0_88:
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r254}, %fd123; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r253, hi}, %fd123; 
	}
	// inline asm
	bfe.u32 	%r255, %r254, 20, 11;
	setp.ne.s32	%p109, %r255, 0;
	@%p109 bra 	BB0_90;

	mov.f64 	%fd654, 0d4350000000000000;
	mul.rn.f64 	%fd653, %fd123, %fd654;
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r254}, %fd653; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r253, hi}, %fd653; 
	}
	// inline asm
	bfe.u32 	%r149, %r254, 20, 11;
	add.s32 	%r255, %r149, -54;

BB0_90:
	and.b32  	%r152, %r254, -2146435073;
	or.b32  	%r151, %r152, 1072693248;
	// inline asm
	mov.b64 	%fd1548, {%r253, %r151};
	// inline asm
	add.s32 	%r256, %r255, -1023;
	setp.lt.u32	%p110, %r151, 1073127583;
	@%p110 bra 	BB0_92;

	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r153, hi}, %fd1548; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r154}, %fd1548; 
	}
	// inline asm
	add.s32 	%r156, %r154, -1048576;
	// inline asm
	mov.b64 	%fd1548, {%r153, %r156};
	// inline asm
	add.s32 	%r256, %r255, -1022;

BB0_92:
	add.f64 	%fd743, %fd1548, 0d3FF0000000000000;
	rcp.rn.f64 	%fd744, %fd743;
	add.f64 	%fd685, %fd1548, 0dBFF0000000000000;
	mul.rn.f64 	%fd745, %fd685, %fd744;
	add.f64 	%fd733, %fd745, %fd745;
	mul.rn.f64 	%fd681, %fd733, %fd733;
	mov.f64 	%fd660, 0d3EB0F5FF7D2CAFE2;
	mov.f64 	%fd662, 0d3ED0F5D241AD3B5A;
	// inline asm
	fma.rn.f64 	%fd659, %fd660, %fd681, %fd662;
	// inline asm
	mov.f64 	%fd666, 0d3EF3B20A75488A3F;
	// inline asm
	fma.rn.f64 	%fd663, %fd659, %fd681, %fd666;
	// inline asm
	mov.f64 	%fd670, 0d3F1745CDE4FAECD5;
	// inline asm
	fma.rn.f64 	%fd667, %fd663, %fd681, %fd670;
	// inline asm
	mov.f64 	%fd674, 0d3F3C71C7258A578B;
	// inline asm
	fma.rn.f64 	%fd671, %fd667, %fd681, %fd674;
	// inline asm
	mov.f64 	%fd678, 0d3F6249249242B910;
	// inline asm
	fma.rn.f64 	%fd675, %fd671, %fd681, %fd678;
	// inline asm
	mov.f64 	%fd682, 0d3F89999999999DFB;
	// inline asm
	fma.rn.f64 	%fd679, %fd675, %fd681, %fd682;
	// inline asm
	mul.rn.f64 	%fd746, %fd679, %fd681;
	sub.f64 	%fd747, %fd685, %fd733;
	mul.rn.f64 	%fd686, %fd641, %fd747;
	neg.f64 	%fd684, %fd733;
	// inline asm
	fma.rn.f64 	%fd683, %fd684, %fd685, %fd686;
	// inline asm
	mul.rn.f64 	%fd729, %fd744, %fd683;
	add.f64 	%fd748, %fd746, 0d3FB5555555555555;
	mov.f64 	%fd749, 0d3FB5555555555555;
	sub.f64 	%fd750, %fd749, %fd748;
	add.f64 	%fd751, %fd746, %fd750;
	add.f64 	%fd752, %fd751, 0d0000000000000000;
	add.f64 	%fd753, %fd752, 0dBC46A4CB00B9E7B0;
	add.f64 	%fd696, %fd748, %fd753;
	sub.f64 	%fd754, %fd748, %fd696;
	add.f64 	%fd700, %fd753, %fd754;
	mul.rn.f64 	%fd755, %fd696, %fd733;
	neg.f64 	%fd690, %fd755;
	// inline asm
	fma.rn.f64 	%fd687, %fd696, %fd733, %fd690;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd691, %fd700, %fd729, %fd687;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd695, %fd696, %fd729, %fd691;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd699, %fd700, %fd733, %fd695;
	// inline asm
	add.f64 	%fd712, %fd755, %fd699;
	sub.f64 	%fd756, %fd755, %fd712;
	add.f64 	%fd716, %fd699, %fd756;
	mul.rn.f64 	%fd757, %fd712, %fd733;
	neg.f64 	%fd706, %fd757;
	// inline asm
	fma.rn.f64 	%fd703, %fd712, %fd733, %fd706;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd707, %fd716, %fd729, %fd703;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd711, %fd712, %fd729, %fd707;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd715, %fd716, %fd733, %fd711;
	// inline asm
	add.f64 	%fd728, %fd757, %fd715;
	sub.f64 	%fd758, %fd757, %fd728;
	add.f64 	%fd732, %fd715, %fd758;
	mul.rn.f64 	%fd759, %fd728, %fd733;
	neg.f64 	%fd722, %fd759;
	// inline asm
	fma.rn.f64 	%fd719, %fd728, %fd733, %fd722;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd723, %fd732, %fd729, %fd719;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd727, %fd728, %fd729, %fd723;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd731, %fd732, %fd733, %fd727;
	// inline asm
	add.f64 	%fd760, %fd759, %fd731;
	sub.f64 	%fd761, %fd759, %fd760;
	add.f64 	%fd762, %fd731, %fd761;
	add.f64 	%fd763, %fd733, %fd760;
	sub.f64 	%fd764, %fd733, %fd763;
	add.f64 	%fd765, %fd760, %fd764;
	add.f64 	%fd766, %fd762, %fd765;
	add.f64 	%fd767, %fd729, %fd766;
	add.f64 	%fd768, %fd763, %fd767;
	sub.f64 	%fd769, %fd763, %fd768;
	add.f64 	%fd770, %fd767, %fd769;
	cvt.rn.f64.s32	%fd771, %r256;
	mov.f64 	%fd772, 0d3FE62E42FEFA3000;
	mul.rn.f64 	%fd773, %fd771, %fd772;
	mov.f64 	%fd774, 0d3D53DE6AF278ECE6;
	mul.rn.f64 	%fd775, %fd771, %fd774;
	add.f64 	%fd776, %fd773, %fd768;
	sub.f64 	%fd777, %fd773, %fd776;
	add.f64 	%fd778, %fd768, %fd777;
	add.f64 	%fd779, %fd770, %fd778;
	add.f64 	%fd780, %fd775, %fd779;
	add.f64 	%fd736, %fd776, %fd780;
	sub.f64 	%fd781, %fd776, %fd736;
	add.f64 	%fd740, %fd780, %fd781;
	mul.rn.f64 	%fd782, %fd736, %fd641;
	neg.f64 	%fd738, %fd782;
	// inline asm
	fma.rn.f64 	%fd735, %fd736, %fd641, %fd738;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd739, %fd740, %fd641, %fd735;
	// inline asm
	add.f64 	%fd128, %fd782, %fd739;
	sub.f64 	%fd783, %fd782, %fd128;
	add.f64 	%fd129, %fd739, %fd783;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r50}, %fd128;
	}
	mov.b32 	 %f1, %r50;
	abs.f32 	%f2, %f1;
	setp.lt.f32	%p111, %f2, 0f40874911;
	@%p111 bra 	BB0_94;
	bra.uni 	BB0_93;

BB0_94:
	mov.f64 	%fd787, 0d3FF71547652B82FE;
	mul.rn.f64 	%fd788, %fd128, %fd787;
	mov.f64 	%fd789, 0d4338000000000000;
	add.rn.f64 	%fd790, %fd788, %fd789;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r51, %temp}, %fd790;
	}
	mov.f64 	%fd791, 0dC338000000000000;
	add.rn.f64 	%fd792, %fd790, %fd791;
	mov.f64 	%fd793, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd794, %fd792, %fd793, %fd128;
	mov.f64 	%fd795, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd796, %fd792, %fd795, %fd794;
	mov.f64 	%fd797, 0d3E928AF3FCA213EA;
	mov.f64 	%fd798, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd799, %fd798, %fd796, %fd797;
	mov.f64 	%fd800, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd801, %fd799, %fd796, %fd800;
	mov.f64 	%fd802, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd803, %fd801, %fd796, %fd802;
	mov.f64 	%fd804, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd805, %fd803, %fd796, %fd804;
	mov.f64 	%fd806, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd807, %fd805, %fd796, %fd806;
	mov.f64 	%fd808, 0d3F81111111122322;
	fma.rn.f64 	%fd809, %fd807, %fd796, %fd808;
	mov.f64 	%fd810, 0d3FA55555555502A1;
	fma.rn.f64 	%fd811, %fd809, %fd796, %fd810;
	mov.f64 	%fd812, 0d3FC5555555555511;
	fma.rn.f64 	%fd813, %fd811, %fd796, %fd812;
	mov.f64 	%fd814, 0d3FE000000000000B;
	fma.rn.f64 	%fd815, %fd813, %fd796, %fd814;
	mov.f64 	%fd816, 0d3FF0000000000000;
	fma.rn.f64 	%fd817, %fd815, %fd796, %fd816;
	fma.rn.f64 	%fd1549, %fd817, %fd796, %fd816;
	abs.s32 	%r157, %r51;
	setp.lt.s32	%p114, %r157, 1023;
	@%p114 bra 	BB0_96;
	bra.uni 	BB0_95;

BB0_96:
	shl.b32 	%r163, %r51, 20;
	add.s32 	%r257, %r163, 1072693248;
	bra.uni 	BB0_97;

BB0_93:
	setp.lt.s32	%p112, %r50, 0;
	selp.f64	%fd784, 0d0000000000000000, 0d7FF0000000000000, %p112;
	abs.f64 	%fd785, %fd128;
	setp.gtu.f64	%p113, %fd785, 0d7FF0000000000000;
	add.f64 	%fd786, %fd128, %fd128;
	selp.f64	%fd1552, %fd786, %fd784, %p113;
	bra.uni 	BB0_98;

BB0_95:
	add.s32 	%r158, %r51, 2046;
	shl.b32 	%r159, %r158, 19;
	and.b32  	%r160, %r159, -1048576;
	shl.b32 	%r161, %r158, 20;
	sub.s32 	%r257, %r161, %r160;
	mov.u32 	%r162, 0;
	mov.b64 	%fd818, {%r162, %r160};
	mul.f64 	%fd1549, %fd1549, %fd818;

BB0_97:
	mov.u32 	%r164, 0;
	mov.b64 	%fd819, {%r164, %r257};
	mul.f64 	%fd1552, %fd1549, %fd819;

BB0_98:
	abs.f64 	%fd820, %fd1552;
	setp.eq.f64	%p115, %fd820, 0d7FF0000000000000;
	@%p115 bra 	BB0_100;

	// inline asm
	fma.rn.f64 	%fd1552, %fd1552, %fd129, %fd1552;
	// inline asm

BB0_100:
	abs.f64 	%fd1462, %fd121;
	setp.geu.f64	%p378, %fd1462, 0d0000000000000000;
	setp.neu.f64	%p116, %fd124, 0d3FF0000000000000;
	or.pred  	%p118, %p378, %p116;
	@%p118 bra 	BB0_107;

	mov.b64 	 %rd38, %fd1552;
	xor.b64  	%rd39, %rd38, -9223372036854775808;
	mov.b64 	 %fd1552, %rd39;

BB0_107:
	abs.f64 	%fd1466, %fd121;
	setp.eq.f64	%p379, %fd1466, 0d3FF0000000000000;
	mov.f64 	%fd1559, 0d3FF0000000000000;
	mov.f64 	%fd827, 0d40F0000000000000;
	mov.f64 	%fd828, 0d0000000000000000;
	mul.rn.f64 	%fd145, %fd828, %fd827;
	setp.eq.f64	%p122, %fd145, 0d0000000000000000;
	or.pred  	%p124, %p379, %p122;
	@%p124 bra 	BB0_144;

	abs.f64 	%fd1467, %fd121;
	abs.f64 	%fd146, %fd1467;
	setp.gtu.f64	%p125, %fd146, 0d7FF0000000000000;
	@%p125 bra 	BB0_143;

	abs.f64 	%fd147, %fd145;
	setp.gtu.f64	%p126, %fd147, 0d7FF0000000000000;
	@%p126 bra 	BB0_143;
	bra.uni 	BB0_110;

BB0_143:
	abs.f64 	%fd1476, %fd121;
	add.f64 	%fd1559, %fd1476, %fd145;
	bra.uni 	BB0_144;

BB0_110:
	abs.f64 	%fd1468, %fd121;
	setp.eq.f64	%p127, %fd1468, 0d7FF0000000000000;
	@%p127 bra 	BB0_142;
	bra.uni 	BB0_111;

BB0_142:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r186}, %fd145;
	}
	setp.gt.s32	%p151, %r186, -1;
	selp.f64	%fd1559, 0d7FF0000000000000, 0d0000000000000000, %p151;
	bra.uni 	BB0_144;

BB0_111:
	setp.eq.f64	%p128, %fd147, 0d7FF0000000000000;
	@%p128 bra 	BB0_139;
	bra.uni 	BB0_112;

BB0_139:
	abs.f64 	%fd1475, %fd121;
	mov.f64 	%fd1559, 0d3FF0000000000000;
	setp.eq.f64	%p148, %fd1475, 0dBFF0000000000000;
	@%p148 bra 	BB0_144;

	setp.gt.f64	%p149, %fd146, 0d3FF0000000000000;
	selp.f64	%fd1559, 0d7FF0000000000000, 0d0000000000000000, %p149;
	setp.geu.f64	%p150, %fd145, 0d0000000000000000;
	@%p150 bra 	BB0_144;

	rcp.rn.f64 	%fd1559, %fd1559;
	bra.uni 	BB0_144;

BB0_112:
	abs.f64 	%fd1469, %fd121;
	mov.f64 	%fd829, 0d3FE0000000000000;
	mul.rn.f64 	%fd830, %fd829, %fd145;
	cvt.rzi.f64.f64	%fd831, %fd830;
	mov.f64 	%fd832, 0d4000000000000000;
	mul.rn.f64 	%fd833, %fd832, %fd831;
	sub.f64 	%fd834, %fd145, %fd833;
	abs.f64 	%fd148, %fd834;
	setp.eq.f64	%p129, %fd1469, 0d0000000000000000;
	@%p129 bra 	BB0_137;
	bra.uni 	BB0_113;

BB0_137:
	abs.f64 	%fd1474, %fd121;
	setp.eq.f64	%p146, %fd148, 0d3FF0000000000000;
	selp.f64	%fd1559, %fd1474, 0d0000000000000000, %p146;
	setp.geu.f64	%p147, %fd145, 0d0000000000000000;
	@%p147 bra 	BB0_144;

	rcp.rn.f64 	%fd1559, %fd1559;
	bra.uni 	BB0_144;

BB0_113:
	abs.f64 	%fd1470, %fd121;
	setp.eq.f64	%p130, %fd1470, 0dFFF0000000000000;
	@%p130 bra 	BB0_132;
	bra.uni 	BB0_114;

BB0_132:
	setp.lt.f64	%p144, %fd145, 0d0000000000000000;
	@%p144 bra 	BB0_134;
	bra.uni 	BB0_133;

BB0_134:
	abs.f64 	%fd1473, %fd121;
	mov.f64 	%fd1012, 0dBFF0000000000000;
	div.rn.f64 	%fd1559, %fd1012, %fd1473;
	bra.uni 	BB0_135;

BB0_114:
	abs.f64 	%fd1471, %fd121;
	setp.geu.f64	%p131, %fd1471, 0d0000000000000000;
	@%p131 bra 	BB0_116;

	cvt.rzi.f64.f64	%fd836, %fd145;
	setp.neu.f64	%p132, %fd836, %fd145;
	mov.f64 	%fd1559, 0dFFF8000000000000;
	@%p132 bra 	BB0_144;

BB0_116:
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r259}, %fd146; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r258, hi}, %fd146; 
	}
	// inline asm
	bfe.u32 	%r260, %r259, 20, 11;
	setp.ne.s32	%p133, %r260, 0;
	@%p133 bra 	BB0_118;

	mov.f64 	%fd841, 0d4350000000000000;
	mul.rn.f64 	%fd840, %fd146, %fd841;
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r259}, %fd840; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r258, hi}, %fd840; 
	}
	// inline asm
	bfe.u32 	%r170, %r259, 20, 11;
	add.s32 	%r260, %r170, -54;

BB0_118:
	and.b32  	%r173, %r259, -2146435073;
	or.b32  	%r172, %r173, 1072693248;
	// inline asm
	mov.b64 	%fd1553, {%r258, %r172};
	// inline asm
	add.s32 	%r261, %r260, -1023;
	setp.lt.u32	%p134, %r172, 1073127583;
	@%p134 bra 	BB0_120;

	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r174, hi}, %fd1553; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r175}, %fd1553; 
	}
	// inline asm
	add.s32 	%r177, %r175, -1048576;
	// inline asm
	mov.b64 	%fd1553, {%r174, %r177};
	// inline asm
	add.s32 	%r261, %r260, -1022;

BB0_120:
	add.f64 	%fd922, %fd1553, 0d3FF0000000000000;
	rcp.rn.f64 	%fd923, %fd922;
	add.f64 	%fd872, %fd1553, 0dBFF0000000000000;
	mul.rn.f64 	%fd924, %fd872, %fd923;
	add.f64 	%fd920, %fd924, %fd924;
	mul.rn.f64 	%fd868, %fd920, %fd920;
	mov.f64 	%fd847, 0d3EB0F5FF7D2CAFE2;
	mov.f64 	%fd849, 0d3ED0F5D241AD3B5A;
	// inline asm
	fma.rn.f64 	%fd846, %fd847, %fd868, %fd849;
	// inline asm
	mov.f64 	%fd853, 0d3EF3B20A75488A3F;
	// inline asm
	fma.rn.f64 	%fd850, %fd846, %fd868, %fd853;
	// inline asm
	mov.f64 	%fd857, 0d3F1745CDE4FAECD5;
	// inline asm
	fma.rn.f64 	%fd854, %fd850, %fd868, %fd857;
	// inline asm
	mov.f64 	%fd861, 0d3F3C71C7258A578B;
	// inline asm
	fma.rn.f64 	%fd858, %fd854, %fd868, %fd861;
	// inline asm
	mov.f64 	%fd865, 0d3F6249249242B910;
	// inline asm
	fma.rn.f64 	%fd862, %fd858, %fd868, %fd865;
	// inline asm
	mov.f64 	%fd869, 0d3F89999999999DFB;
	// inline asm
	fma.rn.f64 	%fd866, %fd862, %fd868, %fd869;
	// inline asm
	mul.rn.f64 	%fd925, %fd866, %fd868;
	sub.f64 	%fd926, %fd872, %fd920;
	mul.rn.f64 	%fd873, %fd832, %fd926;
	neg.f64 	%fd871, %fd920;
	// inline asm
	fma.rn.f64 	%fd870, %fd871, %fd872, %fd873;
	// inline asm
	mul.rn.f64 	%fd916, %fd923, %fd870;
	add.f64 	%fd928, %fd925, 0d3FB5555555555555;
	mov.f64 	%fd929, 0d3FB5555555555555;
	sub.f64 	%fd930, %fd929, %fd928;
	add.f64 	%fd931, %fd925, %fd930;
	add.f64 	%fd932, %fd931, 0d0000000000000000;
	add.f64 	%fd933, %fd932, 0dBC46A4CB00B9E7B0;
	add.f64 	%fd883, %fd928, %fd933;
	sub.f64 	%fd934, %fd928, %fd883;
	add.f64 	%fd887, %fd933, %fd934;
	mul.rn.f64 	%fd935, %fd883, %fd920;
	neg.f64 	%fd877, %fd935;
	// inline asm
	fma.rn.f64 	%fd874, %fd883, %fd920, %fd877;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd878, %fd887, %fd916, %fd874;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd882, %fd883, %fd916, %fd878;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd886, %fd887, %fd920, %fd882;
	// inline asm
	add.f64 	%fd899, %fd935, %fd886;
	sub.f64 	%fd936, %fd935, %fd899;
	add.f64 	%fd903, %fd886, %fd936;
	mul.rn.f64 	%fd937, %fd899, %fd920;
	neg.f64 	%fd893, %fd937;
	// inline asm
	fma.rn.f64 	%fd890, %fd899, %fd920, %fd893;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd894, %fd903, %fd916, %fd890;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd898, %fd899, %fd916, %fd894;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd902, %fd903, %fd920, %fd898;
	// inline asm
	add.f64 	%fd915, %fd937, %fd902;
	sub.f64 	%fd938, %fd937, %fd915;
	add.f64 	%fd919, %fd902, %fd938;
	mul.rn.f64 	%fd939, %fd915, %fd920;
	neg.f64 	%fd909, %fd939;
	// inline asm
	fma.rn.f64 	%fd906, %fd915, %fd920, %fd909;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd910, %fd919, %fd916, %fd906;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd914, %fd915, %fd916, %fd910;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd918, %fd919, %fd920, %fd914;
	// inline asm
	add.f64 	%fd940, %fd939, %fd918;
	sub.f64 	%fd941, %fd939, %fd940;
	add.f64 	%fd942, %fd918, %fd941;
	add.f64 	%fd943, %fd920, %fd940;
	sub.f64 	%fd944, %fd920, %fd943;
	add.f64 	%fd945, %fd940, %fd944;
	add.f64 	%fd946, %fd942, %fd945;
	add.f64 	%fd947, %fd916, %fd946;
	add.f64 	%fd948, %fd943, %fd947;
	sub.f64 	%fd949, %fd943, %fd948;
	add.f64 	%fd950, %fd947, %fd949;
	cvt.rn.f64.s32	%fd951, %r261;
	mov.f64 	%fd952, 0d3FE62E42FEFA3000;
	mul.rn.f64 	%fd953, %fd951, %fd952;
	mov.f64 	%fd954, 0d3D53DE6AF278ECE6;
	mul.rn.f64 	%fd955, %fd951, %fd954;
	add.f64 	%fd152, %fd953, %fd948;
	sub.f64 	%fd956, %fd953, %fd152;
	add.f64 	%fd957, %fd948, %fd956;
	add.f64 	%fd958, %fd950, %fd957;
	add.f64 	%fd153, %fd955, %fd958;
	setp.leu.f64	%p135, %fd147, 0d7F0D2A1BE4048F90;
	@%p135 bra 	BB0_122;

	mov.f64 	%fd959, 0d3F20000000000000;
	mul.rn.f64 	%fd145, %fd145, %fd959;

BB0_122:
	add.f64 	%fd961, %fd152, %fd153;
	mul.rn.f64 	%fd968, %fd961, %fd145;
	neg.f64 	%fd963, %fd968;
	// inline asm
	fma.rn.f64 	%fd960, %fd961, %fd145, %fd963;
	// inline asm
	sub.f64 	%fd969, %fd152, %fd961;
	add.f64 	%fd965, %fd153, %fd969;
	// inline asm
	fma.rn.f64 	%fd964, %fd965, %fd145, %fd960;
	// inline asm
	add.f64 	%fd156, %fd968, %fd964;
	sub.f64 	%fd970, %fd968, %fd156;
	add.f64 	%fd157, %fd964, %fd970;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r67}, %fd156;
	}
	mov.b32 	 %f3, %r67;
	abs.f32 	%f4, %f3;
	setp.lt.f32	%p136, %f4, 0f40874911;
	@%p136 bra 	BB0_124;
	bra.uni 	BB0_123;

BB0_124:
	mov.f64 	%fd974, 0d3FF71547652B82FE;
	mul.rn.f64 	%fd975, %fd156, %fd974;
	mov.f64 	%fd976, 0d4338000000000000;
	add.rn.f64 	%fd977, %fd975, %fd976;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r68, %temp}, %fd977;
	}
	mov.f64 	%fd978, 0dC338000000000000;
	add.rn.f64 	%fd979, %fd977, %fd978;
	mov.f64 	%fd980, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd981, %fd979, %fd980, %fd156;
	mov.f64 	%fd982, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd983, %fd979, %fd982, %fd981;
	mov.f64 	%fd984, 0d3E928AF3FCA213EA;
	mov.f64 	%fd985, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd986, %fd985, %fd983, %fd984;
	mov.f64 	%fd987, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd988, %fd986, %fd983, %fd987;
	mov.f64 	%fd989, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd990, %fd988, %fd983, %fd989;
	mov.f64 	%fd991, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd992, %fd990, %fd983, %fd991;
	mov.f64 	%fd993, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd994, %fd992, %fd983, %fd993;
	mov.f64 	%fd995, 0d3F81111111122322;
	fma.rn.f64 	%fd996, %fd994, %fd983, %fd995;
	mov.f64 	%fd997, 0d3FA55555555502A1;
	fma.rn.f64 	%fd998, %fd996, %fd983, %fd997;
	mov.f64 	%fd999, 0d3FC5555555555511;
	fma.rn.f64 	%fd1000, %fd998, %fd983, %fd999;
	mov.f64 	%fd1001, 0d3FE000000000000B;
	fma.rn.f64 	%fd1002, %fd1000, %fd983, %fd1001;
	mov.f64 	%fd1003, 0d3FF0000000000000;
	fma.rn.f64 	%fd1004, %fd1002, %fd983, %fd1003;
	fma.rn.f64 	%fd1555, %fd1004, %fd983, %fd1003;
	abs.s32 	%r178, %r68;
	setp.lt.s32	%p139, %r178, 1023;
	@%p139 bra 	BB0_126;
	bra.uni 	BB0_125;

BB0_126:
	shl.b32 	%r184, %r68, 20;
	add.s32 	%r262, %r184, 1072693248;
	bra.uni 	BB0_127;

BB0_133:
	abs.f64 	%fd1472, %fd121;
	neg.f64 	%fd1559, %fd1472;

BB0_135:
	setp.neu.f64	%p145, %fd148, 0d3FF0000000000000;
	@%p145 bra 	BB0_144;

	mov.b64 	 %rd44, %fd1559;
	xor.b64  	%rd45, %rd44, -9223372036854775808;
	mov.b64 	 %fd1559, %rd45;
	bra.uni 	BB0_144;

BB0_123:
	setp.lt.s32	%p137, %r67, 0;
	selp.f64	%fd971, 0d0000000000000000, 0d7FF0000000000000, %p137;
	abs.f64 	%fd972, %fd156;
	setp.gtu.f64	%p138, %fd972, 0d7FF0000000000000;
	add.f64 	%fd973, %fd156, %fd156;
	selp.f64	%fd1559, %fd973, %fd971, %p138;
	bra.uni 	BB0_128;

BB0_125:
	add.s32 	%r179, %r68, 2046;
	shl.b32 	%r180, %r179, 19;
	and.b32  	%r181, %r180, -1048576;
	shl.b32 	%r182, %r179, 20;
	sub.s32 	%r262, %r182, %r181;
	mov.u32 	%r183, 0;
	mov.b64 	%fd1005, {%r183, %r181};
	mul.f64 	%fd1555, %fd1555, %fd1005;

BB0_127:
	mov.u32 	%r185, 0;
	mov.b64 	%fd1006, {%r185, %r262};
	mul.f64 	%fd1559, %fd1555, %fd1006;

BB0_128:
	abs.f64 	%fd1007, %fd1559;
	setp.eq.f64	%p140, %fd1007, 0d7FF0000000000000;
	@%p140 bra 	BB0_130;

	// inline asm
	fma.rn.f64 	%fd1559, %fd1559, %fd157, %fd1559;
	// inline asm

BB0_130:
	setp.neu.f64	%p141, %fd148, 0d3FF0000000000000;
	or.pred  	%p143, %p131, %p141;
	@%p143 bra 	BB0_144;

	mov.b64 	 %rd42, %fd1559;
	xor.b64  	%rd43, %rd42, -9223372036854775808;
	mov.b64 	 %fd1559, %rd43;

BB0_144:
	mul.rn.f64 	%fd1560, %fd1552, %fd1559;

BB0_145:
	add.f64 	%fd1561, %fd1560, 0d0000000000000000;

BB0_146:
	mov.b32	%r240, %envreg3;
	mov.u32 	%r239, %ntid.x;
	mov.u32 	%r238, %ctaid.x;
	mov.u32 	%r237, %tid.x;
	mad.lo.s32 	%r236, %r238, %r239, %r240;
	add.s32 	%r235, %r236, %r237;
	setp.gt.s32	%p380, %r235, 4;
	@%p380 bra 	BB0_226;

	ld.global.f64 	%fd182, [%rd2];
	abs.f64 	%fd183, %fd182;
	setp.gtu.f64	%p153, %fd183, 0d7FF0000000000000;
	@%p153 bra 	BB0_226;

	setp.lt.f64	%p154, %fd182, 0d0000000000000000;
	setp.lt.f64	%p155, %fd115, 0d0000000000000000;
	and.pred  	%p156, %p154, %p155;
	@%p156 bra 	BB0_150;

	setp.gt.f64	%p157, %fd182, 0d0000000000000000;
	setp.gt.f64	%p158, %fd115, 0d0000000000000000;
	and.pred  	%p159, %p157, %p158;
	@!%p159 bra 	BB0_158;
	bra.uni 	BB0_150;

BB0_150:
	setp.eq.f64	%p160, %fd182, %fd115;
	mov.f64 	%fd187, 0d0000000000000000;
	@%p160 bra 	BB0_159;

	setp.eq.f64	%p161, %fd182, 0d0000000000000000;
	setp.eq.f64	%p162, %fd115, 0d0000000000000000;
	or.pred  	%p163, %p161, %p162;
	@%p163 bra 	BB0_158;

	sub.f64 	%fd1015, %fd182, %fd115;
	abs.f64 	%fd184, %fd1015;
	abs.f64 	%fd1016, %fd184;
	setp.geu.f64	%p164, %fd1016, 0d7FF0000000000000;
	mul.f64 	%fd1017, %fd183, 0d3D30000000000000;
	setp.gt.f64	%p165, %fd184, %fd1017;
	or.pred  	%p166, %p164, %p165;
	@%p166 bra 	BB0_158;

	abs.f64 	%fd185, %fd115;
	mul.f64 	%fd1018, %fd185, 0d3D30000000000000;
	setp.gt.f64	%p167, %fd184, %fd1018;
	@%p167 bra 	BB0_158;

	setp.gtu.f64	%p168, %fd184, 0d433FFFFFFFFFFFFF;
	@%p168 bra 	BB0_278;

	cvt.rzi.s64.f64	%rd46, %fd184;
	setp.gt.s64	%p169, %rd46, 9007199254740991;
	cvt.rn.f64.s64	%fd1019, %rd46;
	setp.ne.f64	%p170, %fd1019, %fd184;
	or.pred  	%p171, %p169, %p170;
	setp.gtu.f64	%p172, %fd183, 0d433FFFFFFFFFFFFF;
	or.pred  	%p173, %p171, %p172;
	@%p173 bra 	BB0_278;

	cvt.rzi.s64.f64	%rd47, %fd183;
	setp.gt.s64	%p174, %rd47, 9007199254740991;
	cvt.rn.f64.s64	%fd1020, %rd47;
	setp.ne.f64	%p175, %fd1020, %fd183;
	or.pred  	%p176, %p174, %p175;
	setp.gtu.f64	%p177, %fd185, 0d433FFFFFFFFFFFFF;
	or.pred  	%p178, %p176, %p177;
	@%p178 bra 	BB0_278;
	bra.uni 	BB0_157;

BB0_278:
	mul.f64 	%fd1026, %fd183, 0d3CF0000000000000;
	setp.geu.f64	%p186, %fd184, %fd1026;
	mul.f64 	%fd1027, %fd185, 0d3CF0000000000000;
	setp.geu.f64	%p187, %fd184, %fd1027;
	or.pred  	%p188, %p186, %p187;
	@!%p188 bra 	BB0_159;
	bra.uni 	BB0_158;

BB0_157:
	cvt.rzi.s64.f64	%rd48, %fd185;
	setp.lt.s64	%p179, %rd48, 9007199254740992;
	cvt.rn.f64.s64	%fd1022, %rd48;
	setp.equ.f64	%p180, %fd1022, %fd185;
	and.pred  	%p181, %p179, %p180;
	mul.f64 	%fd1023, %fd183, 0d3CF0000000000000;
	setp.geu.f64	%p182, %fd184, %fd1023;
	or.pred  	%p183, %p181, %p182;
	mul.f64 	%fd1024, %fd185, 0d3CF0000000000000;
	setp.geu.f64	%p184, %fd184, %fd1024;
	or.pred  	%p185, %p184, %p183;
	@%p185 bra 	BB0_158;
	bra.uni 	BB0_159;

BB0_158:
	sub.f64 	%fd187, %fd182, %fd115;

BB0_159:
	abs.f64 	%fd188, %fd187;
	setp.gtu.f64	%p189, %fd188, 0d7FF0000000000000;
	mov.f64 	%fd1575, 0dFFF8000000000000;
	@%p189 bra 	BB0_225;

	setp.eq.f64	%p190, %fd187, 0d0000000000000000;
	mov.f64 	%fd1575, 0d0000000000000000;
	@%p190 bra 	BB0_225;

	setp.eq.f64	%p191, %fd188, 0d3FF0000000000000;
	mov.f64 	%fd1567, 0d3FF0000000000000;
	@%p191 bra 	BB0_187;

	abs.f64 	%fd189, %fd188;
	setp.gtu.f64	%p192, %fd189, 0d7FF0000000000000;
	@%p192 bra 	BB0_186;
	bra.uni 	BB0_163;

BB0_186:
	add.f64 	%fd1567, %fd188, 0d4000000000000000;
	bra.uni 	BB0_187;

BB0_163:
	setp.eq.f64	%p193, %fd188, 0d7FF0000000000000;
	@%p193 bra 	BB0_185;
	bra.uni 	BB0_164;

BB0_185:
	mov.f64 	%fd1215, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r207}, %fd1215;
	}
	setp.gt.s32	%p210, %r207, -1;
	selp.f64	%fd1567, 0d7FF0000000000000, 0d0000000000000000, %p210;
	bra.uni 	BB0_187;

BB0_164:
	mov.f64 	%fd1031, 0d4000000000000000;
	mov.f64 	%fd1032, 0d3FE0000000000000;
	mul.rn.f64 	%fd1033, %fd1032, %fd1031;
	cvt.rzi.f64.f64	%fd1034, %fd1033;
	mul.rn.f64 	%fd1035, %fd1031, %fd1034;
	sub.f64 	%fd1036, %fd1031, %fd1035;
	abs.f64 	%fd190, %fd1036;
	setp.eq.f64	%p194, %fd188, 0d0000000000000000;
	@%p194 bra 	BB0_184;
	bra.uni 	BB0_165;

BB0_184:
	setp.eq.f64	%p209, %fd190, 0d3FF0000000000000;
	selp.f64	%fd1567, %fd188, 0d0000000000000000, %p209;
	bra.uni 	BB0_187;

BB0_165:
	setp.eq.f64	%p195, %fd188, 0dFFF0000000000000;
	@%p195 bra 	BB0_182;
	bra.uni 	BB0_166;

BB0_182:
	neg.f64 	%fd1567, %fd188;
	setp.neu.f64	%p208, %fd190, 0d3FF0000000000000;
	@%p208 bra 	BB0_187;

	mov.b64 	 %rd51, %fd1567;
	xor.b64  	%rd52, %rd51, -9223372036854775808;
	mov.b64 	 %fd1567, %rd52;
	bra.uni 	BB0_187;

BB0_166:
	setp.geu.f64	%p196, %fd188, 0d0000000000000000;
	@%p196 bra 	BB0_168;

	cvt.rzi.f64.f64	%fd1039, %fd1031;
	setp.neu.f64	%p197, %fd1039, 0d4000000000000000;
	mov.f64 	%fd1567, 0dFFF8000000000000;
	@%p197 bra 	BB0_187;

BB0_168:
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r264}, %fd189; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r263, hi}, %fd189; 
	}
	// inline asm
	bfe.u32 	%r265, %r264, 20, 11;
	setp.ne.s32	%p198, %r265, 0;
	@%p198 bra 	BB0_170;

	mov.f64 	%fd1044, 0d4350000000000000;
	mul.rn.f64 	%fd1043, %fd189, %fd1044;
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r264}, %fd1043; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r263, hi}, %fd1043; 
	}
	// inline asm
	bfe.u32 	%r191, %r264, 20, 11;
	add.s32 	%r265, %r191, -54;

BB0_170:
	add.s32 	%r266, %r265, -1023;
	and.b32  	%r194, %r264, -2146435073;
	or.b32  	%r193, %r194, 1072693248;
	// inline asm
	mov.b64 	%fd1563, {%r263, %r193};
	// inline asm
	setp.lt.u32	%p199, %r193, 1073127583;
	@%p199 bra 	BB0_172;

	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r195, hi}, %fd1563; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r196}, %fd1563; 
	}
	// inline asm
	add.s32 	%r198, %r196, -1048576;
	// inline asm
	mov.b64 	%fd1563, {%r195, %r198};
	// inline asm
	add.s32 	%r266, %r265, -1022;

BB0_172:
	add.f64 	%fd1133, %fd1563, 0d3FF0000000000000;
	rcp.rn.f64 	%fd1134, %fd1133;
	add.f64 	%fd1075, %fd1563, 0dBFF0000000000000;
	mul.rn.f64 	%fd1135, %fd1075, %fd1134;
	add.f64 	%fd1123, %fd1135, %fd1135;
	mul.rn.f64 	%fd1071, %fd1123, %fd1123;
	mov.f64 	%fd1050, 0d3EB0F5FF7D2CAFE2;
	mov.f64 	%fd1052, 0d3ED0F5D241AD3B5A;
	// inline asm
	fma.rn.f64 	%fd1049, %fd1050, %fd1071, %fd1052;
	// inline asm
	mov.f64 	%fd1056, 0d3EF3B20A75488A3F;
	// inline asm
	fma.rn.f64 	%fd1053, %fd1049, %fd1071, %fd1056;
	// inline asm
	mov.f64 	%fd1060, 0d3F1745CDE4FAECD5;
	// inline asm
	fma.rn.f64 	%fd1057, %fd1053, %fd1071, %fd1060;
	// inline asm
	mov.f64 	%fd1064, 0d3F3C71C7258A578B;
	// inline asm
	fma.rn.f64 	%fd1061, %fd1057, %fd1071, %fd1064;
	// inline asm
	mov.f64 	%fd1068, 0d3F6249249242B910;
	// inline asm
	fma.rn.f64 	%fd1065, %fd1061, %fd1071, %fd1068;
	// inline asm
	mov.f64 	%fd1072, 0d3F89999999999DFB;
	// inline asm
	fma.rn.f64 	%fd1069, %fd1065, %fd1071, %fd1072;
	// inline asm
	mul.rn.f64 	%fd1136, %fd1069, %fd1071;
	sub.f64 	%fd1137, %fd1075, %fd1123;
	mul.rn.f64 	%fd1076, %fd1031, %fd1137;
	neg.f64 	%fd1074, %fd1123;
	// inline asm
	fma.rn.f64 	%fd1073, %fd1074, %fd1075, %fd1076;
	// inline asm
	mul.rn.f64 	%fd1119, %fd1134, %fd1073;
	add.f64 	%fd1138, %fd1136, 0d3FB5555555555555;
	mov.f64 	%fd1139, 0d3FB5555555555555;
	sub.f64 	%fd1140, %fd1139, %fd1138;
	add.f64 	%fd1141, %fd1136, %fd1140;
	add.f64 	%fd1142, %fd1141, 0d0000000000000000;
	add.f64 	%fd1143, %fd1142, 0dBC46A4CB00B9E7B0;
	add.f64 	%fd1086, %fd1138, %fd1143;
	sub.f64 	%fd1144, %fd1138, %fd1086;
	add.f64 	%fd1090, %fd1143, %fd1144;
	mul.rn.f64 	%fd1145, %fd1086, %fd1123;
	neg.f64 	%fd1080, %fd1145;
	// inline asm
	fma.rn.f64 	%fd1077, %fd1086, %fd1123, %fd1080;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1081, %fd1090, %fd1119, %fd1077;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1085, %fd1086, %fd1119, %fd1081;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1089, %fd1090, %fd1123, %fd1085;
	// inline asm
	add.f64 	%fd1102, %fd1145, %fd1089;
	sub.f64 	%fd1146, %fd1145, %fd1102;
	add.f64 	%fd1106, %fd1089, %fd1146;
	mul.rn.f64 	%fd1147, %fd1102, %fd1123;
	neg.f64 	%fd1096, %fd1147;
	// inline asm
	fma.rn.f64 	%fd1093, %fd1102, %fd1123, %fd1096;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1097, %fd1106, %fd1119, %fd1093;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1101, %fd1102, %fd1119, %fd1097;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1105, %fd1106, %fd1123, %fd1101;
	// inline asm
	add.f64 	%fd1118, %fd1147, %fd1105;
	sub.f64 	%fd1148, %fd1147, %fd1118;
	add.f64 	%fd1122, %fd1105, %fd1148;
	mul.rn.f64 	%fd1149, %fd1118, %fd1123;
	neg.f64 	%fd1112, %fd1149;
	// inline asm
	fma.rn.f64 	%fd1109, %fd1118, %fd1123, %fd1112;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1113, %fd1122, %fd1119, %fd1109;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1117, %fd1118, %fd1119, %fd1113;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1121, %fd1122, %fd1123, %fd1117;
	// inline asm
	add.f64 	%fd1150, %fd1149, %fd1121;
	sub.f64 	%fd1151, %fd1149, %fd1150;
	add.f64 	%fd1152, %fd1121, %fd1151;
	add.f64 	%fd1153, %fd1123, %fd1150;
	sub.f64 	%fd1154, %fd1123, %fd1153;
	add.f64 	%fd1155, %fd1150, %fd1154;
	add.f64 	%fd1156, %fd1152, %fd1155;
	add.f64 	%fd1157, %fd1119, %fd1156;
	add.f64 	%fd1158, %fd1153, %fd1157;
	sub.f64 	%fd1159, %fd1153, %fd1158;
	add.f64 	%fd1160, %fd1157, %fd1159;
	cvt.rn.f64.s32	%fd1161, %r266;
	mov.f64 	%fd1162, 0d3FE62E42FEFA3000;
	mul.rn.f64 	%fd1163, %fd1161, %fd1162;
	mov.f64 	%fd1164, 0d3D53DE6AF278ECE6;
	mul.rn.f64 	%fd1165, %fd1161, %fd1164;
	add.f64 	%fd1166, %fd1163, %fd1158;
	sub.f64 	%fd1167, %fd1163, %fd1166;
	add.f64 	%fd1168, %fd1158, %fd1167;
	add.f64 	%fd1169, %fd1160, %fd1168;
	add.f64 	%fd1170, %fd1165, %fd1169;
	add.f64 	%fd1126, %fd1166, %fd1170;
	sub.f64 	%fd1171, %fd1166, %fd1126;
	add.f64 	%fd1130, %fd1170, %fd1171;
	mul.rn.f64 	%fd1172, %fd1126, %fd1031;
	neg.f64 	%fd1128, %fd1172;
	// inline asm
	fma.rn.f64 	%fd1125, %fd1126, %fd1031, %fd1128;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1129, %fd1130, %fd1031, %fd1125;
	// inline asm
	add.f64 	%fd194, %fd1172, %fd1129;
	sub.f64 	%fd1173, %fd1172, %fd194;
	add.f64 	%fd195, %fd1129, %fd1173;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r84}, %fd194;
	}
	mov.b32 	 %f5, %r84;
	abs.f32 	%f6, %f5;
	setp.lt.f32	%p200, %f6, 0f40874911;
	@%p200 bra 	BB0_174;
	bra.uni 	BB0_173;

BB0_174:
	mov.f64 	%fd1177, 0d3FF71547652B82FE;
	mul.rn.f64 	%fd1178, %fd194, %fd1177;
	mov.f64 	%fd1179, 0d4338000000000000;
	add.rn.f64 	%fd1180, %fd1178, %fd1179;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r85, %temp}, %fd1180;
	}
	mov.f64 	%fd1181, 0dC338000000000000;
	add.rn.f64 	%fd1182, %fd1180, %fd1181;
	mov.f64 	%fd1183, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd1184, %fd1182, %fd1183, %fd194;
	mov.f64 	%fd1185, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd1186, %fd1182, %fd1185, %fd1184;
	mov.f64 	%fd1187, 0d3E928AF3FCA213EA;
	mov.f64 	%fd1188, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd1189, %fd1188, %fd1186, %fd1187;
	mov.f64 	%fd1190, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd1191, %fd1189, %fd1186, %fd1190;
	mov.f64 	%fd1192, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd1193, %fd1191, %fd1186, %fd1192;
	mov.f64 	%fd1194, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd1195, %fd1193, %fd1186, %fd1194;
	mov.f64 	%fd1196, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd1197, %fd1195, %fd1186, %fd1196;
	mov.f64 	%fd1198, 0d3F81111111122322;
	fma.rn.f64 	%fd1199, %fd1197, %fd1186, %fd1198;
	mov.f64 	%fd1200, 0d3FA55555555502A1;
	fma.rn.f64 	%fd1201, %fd1199, %fd1186, %fd1200;
	mov.f64 	%fd1202, 0d3FC5555555555511;
	fma.rn.f64 	%fd1203, %fd1201, %fd1186, %fd1202;
	mov.f64 	%fd1204, 0d3FE000000000000B;
	fma.rn.f64 	%fd1205, %fd1203, %fd1186, %fd1204;
	mov.f64 	%fd1206, 0d3FF0000000000000;
	fma.rn.f64 	%fd1207, %fd1205, %fd1186, %fd1206;
	fma.rn.f64 	%fd1564, %fd1207, %fd1186, %fd1206;
	abs.s32 	%r199, %r85;
	setp.lt.s32	%p203, %r199, 1023;
	@%p203 bra 	BB0_176;
	bra.uni 	BB0_175;

BB0_176:
	shl.b32 	%r205, %r85, 20;
	add.s32 	%r267, %r205, 1072693248;
	bra.uni 	BB0_177;

BB0_173:
	setp.lt.s32	%p201, %r84, 0;
	selp.f64	%fd1174, 0d0000000000000000, 0d7FF0000000000000, %p201;
	abs.f64 	%fd1175, %fd194;
	setp.gtu.f64	%p202, %fd1175, 0d7FF0000000000000;
	add.f64 	%fd1176, %fd194, %fd194;
	selp.f64	%fd1567, %fd1176, %fd1174, %p202;
	bra.uni 	BB0_178;

BB0_175:
	add.s32 	%r200, %r85, 2046;
	shl.b32 	%r201, %r200, 19;
	and.b32  	%r202, %r201, -1048576;
	shl.b32 	%r203, %r200, 20;
	sub.s32 	%r267, %r203, %r202;
	mov.u32 	%r204, 0;
	mov.b64 	%fd1208, {%r204, %r202};
	mul.f64 	%fd1564, %fd1564, %fd1208;

BB0_177:
	mov.u32 	%r206, 0;
	mov.b64 	%fd1209, {%r206, %r267};
	mul.f64 	%fd1567, %fd1564, %fd1209;

BB0_178:
	abs.f64 	%fd1210, %fd1567;
	setp.eq.f64	%p204, %fd1210, 0d7FF0000000000000;
	@%p204 bra 	BB0_180;

	// inline asm
	fma.rn.f64 	%fd1567, %fd1567, %fd195, %fd1567;
	// inline asm

BB0_180:
	abs.f64 	%fd1477, %fd187;
	setp.geu.f64	%p381, %fd1477, 0d0000000000000000;
	setp.neu.f64	%p205, %fd190, 0d3FF0000000000000;
	or.pred  	%p207, %p381, %p205;
	@%p207 bra 	BB0_187;

	mov.b64 	 %rd49, %fd1567;
	xor.b64  	%rd50, %rd49, -9223372036854775808;
	mov.b64 	 %fd1567, %rd50;

BB0_187:
	abs.f64 	%fd1479, %fd187;
	setp.eq.f64	%p382, %fd1479, 0d3FF0000000000000;
	mov.f64 	%fd1574, 0d3FF0000000000000;
	mov.f64 	%fd1217, 0d40F0000000000000;
	mov.f64 	%fd1218, 0d0000000000000000;
	mul.rn.f64 	%fd211, %fd1218, %fd1217;
	setp.eq.f64	%p211, %fd211, 0d0000000000000000;
	or.pred  	%p213, %p382, %p211;
	@%p213 bra 	BB0_224;

	abs.f64 	%fd1480, %fd187;
	abs.f64 	%fd212, %fd1480;
	setp.gtu.f64	%p214, %fd212, 0d7FF0000000000000;
	@%p214 bra 	BB0_223;

	abs.f64 	%fd213, %fd211;
	setp.gtu.f64	%p215, %fd213, 0d7FF0000000000000;
	@%p215 bra 	BB0_223;
	bra.uni 	BB0_190;

BB0_223:
	abs.f64 	%fd1490, %fd187;
	add.f64 	%fd1574, %fd1490, %fd211;
	bra.uni 	BB0_224;

BB0_190:
	abs.f64 	%fd1481, %fd187;
	setp.eq.f64	%p216, %fd1481, 0d7FF0000000000000;
	@%p216 bra 	BB0_222;
	bra.uni 	BB0_191;

BB0_222:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r228}, %fd211;
	}
	setp.gt.s32	%p240, %r228, -1;
	selp.f64	%fd1574, 0d7FF0000000000000, 0d0000000000000000, %p240;
	bra.uni 	BB0_224;

BB0_191:
	setp.eq.f64	%p217, %fd213, 0d7FF0000000000000;
	@%p217 bra 	BB0_219;
	bra.uni 	BB0_192;

BB0_219:
	abs.f64 	%fd1489, %fd187;
	mov.f64 	%fd1574, 0d3FF0000000000000;
	setp.eq.f64	%p237, %fd1489, 0dBFF0000000000000;
	@%p237 bra 	BB0_224;

	setp.gt.f64	%p238, %fd212, 0d3FF0000000000000;
	selp.f64	%fd1574, 0d7FF0000000000000, 0d0000000000000000, %p238;
	setp.geu.f64	%p239, %fd211, 0d0000000000000000;
	@%p239 bra 	BB0_224;

	rcp.rn.f64 	%fd1574, %fd1574;
	bra.uni 	BB0_224;

BB0_192:
	abs.f64 	%fd1482, %fd187;
	mov.f64 	%fd1219, 0d3FE0000000000000;
	mul.rn.f64 	%fd1220, %fd1219, %fd211;
	cvt.rzi.f64.f64	%fd1221, %fd1220;
	mov.f64 	%fd1222, 0d4000000000000000;
	mul.rn.f64 	%fd1223, %fd1222, %fd1221;
	sub.f64 	%fd1224, %fd211, %fd1223;
	abs.f64 	%fd214, %fd1224;
	setp.eq.f64	%p218, %fd1482, 0d0000000000000000;
	@%p218 bra 	BB0_217;
	bra.uni 	BB0_193;

BB0_217:
	abs.f64 	%fd1487, %fd187;
	setp.eq.f64	%p235, %fd214, 0d3FF0000000000000;
	selp.f64	%fd1574, %fd1487, 0d0000000000000000, %p235;
	setp.geu.f64	%p236, %fd211, 0d0000000000000000;
	@%p236 bra 	BB0_224;

	rcp.rn.f64 	%fd1574, %fd1574;
	bra.uni 	BB0_224;

BB0_193:
	abs.f64 	%fd1483, %fd187;
	setp.eq.f64	%p219, %fd1483, 0dFFF0000000000000;
	@%p219 bra 	BB0_212;
	bra.uni 	BB0_194;

BB0_212:
	setp.lt.f64	%p233, %fd211, 0d0000000000000000;
	@%p233 bra 	BB0_214;
	bra.uni 	BB0_213;

BB0_214:
	abs.f64 	%fd1486, %fd187;
	mov.f64 	%fd1402, 0dBFF0000000000000;
	div.rn.f64 	%fd1574, %fd1402, %fd1486;
	bra.uni 	BB0_215;

BB0_194:
	abs.f64 	%fd1484, %fd187;
	setp.geu.f64	%p220, %fd1484, 0d0000000000000000;
	@%p220 bra 	BB0_196;

	cvt.rzi.f64.f64	%fd1226, %fd211;
	setp.neu.f64	%p221, %fd1226, %fd211;
	mov.f64 	%fd1574, 0dFFF8000000000000;
	@%p221 bra 	BB0_224;

BB0_196:
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r269}, %fd212; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r268, hi}, %fd212; 
	}
	// inline asm
	bfe.u32 	%r270, %r269, 20, 11;
	setp.ne.s32	%p222, %r270, 0;
	@%p222 bra 	BB0_198;

	mov.f64 	%fd1231, 0d4350000000000000;
	mul.rn.f64 	%fd1230, %fd212, %fd1231;
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r269}, %fd1230; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r268, hi}, %fd1230; 
	}
	// inline asm
	bfe.u32 	%r212, %r269, 20, 11;
	add.s32 	%r270, %r212, -54;

BB0_198:
	add.s32 	%r271, %r270, -1023;
	and.b32  	%r215, %r269, -2146435073;
	or.b32  	%r214, %r215, 1072693248;
	// inline asm
	mov.b64 	%fd1568, {%r268, %r214};
	// inline asm
	setp.lt.u32	%p223, %r214, 1073127583;
	@%p223 bra 	BB0_200;

	// inline asm
	{ 
	.reg 	.b32 hi; 
	mov.b64 	{%r216, hi}, %fd1568; 
	}
	// inline asm
	// inline asm
	{ 
	.reg 	.b32 lo; 
	mov.b64 	{lo, %r217}, %fd1568; 
	}
	// inline asm
	add.s32 	%r219, %r217, -1048576;
	// inline asm
	mov.b64 	%fd1568, {%r216, %r219};
	// inline asm
	add.s32 	%r271, %r270, -1022;

BB0_200:
	add.f64 	%fd1312, %fd1568, 0d3FF0000000000000;
	rcp.rn.f64 	%fd1313, %fd1312;
	add.f64 	%fd1262, %fd1568, 0dBFF0000000000000;
	mul.rn.f64 	%fd1314, %fd1262, %fd1313;
	add.f64 	%fd1310, %fd1314, %fd1314;
	mul.rn.f64 	%fd1258, %fd1310, %fd1310;
	mov.f64 	%fd1237, 0d3EB0F5FF7D2CAFE2;
	mov.f64 	%fd1239, 0d3ED0F5D241AD3B5A;
	// inline asm
	fma.rn.f64 	%fd1236, %fd1237, %fd1258, %fd1239;
	// inline asm
	mov.f64 	%fd1243, 0d3EF3B20A75488A3F;
	// inline asm
	fma.rn.f64 	%fd1240, %fd1236, %fd1258, %fd1243;
	// inline asm
	mov.f64 	%fd1247, 0d3F1745CDE4FAECD5;
	// inline asm
	fma.rn.f64 	%fd1244, %fd1240, %fd1258, %fd1247;
	// inline asm
	mov.f64 	%fd1251, 0d3F3C71C7258A578B;
	// inline asm
	fma.rn.f64 	%fd1248, %fd1244, %fd1258, %fd1251;
	// inline asm
	mov.f64 	%fd1255, 0d3F6249249242B910;
	// inline asm
	fma.rn.f64 	%fd1252, %fd1248, %fd1258, %fd1255;
	// inline asm
	mov.f64 	%fd1259, 0d3F89999999999DFB;
	// inline asm
	fma.rn.f64 	%fd1256, %fd1252, %fd1258, %fd1259;
	// inline asm
	mul.rn.f64 	%fd1315, %fd1256, %fd1258;
	sub.f64 	%fd1316, %fd1262, %fd1310;
	mul.rn.f64 	%fd1263, %fd1222, %fd1316;
	neg.f64 	%fd1261, %fd1310;
	// inline asm
	fma.rn.f64 	%fd1260, %fd1261, %fd1262, %fd1263;
	// inline asm
	mul.rn.f64 	%fd1306, %fd1313, %fd1260;
	add.f64 	%fd1318, %fd1315, 0d3FB5555555555555;
	mov.f64 	%fd1319, 0d3FB5555555555555;
	sub.f64 	%fd1320, %fd1319, %fd1318;
	add.f64 	%fd1321, %fd1315, %fd1320;
	add.f64 	%fd1322, %fd1321, 0d0000000000000000;
	add.f64 	%fd1323, %fd1322, 0dBC46A4CB00B9E7B0;
	add.f64 	%fd1273, %fd1318, %fd1323;
	sub.f64 	%fd1324, %fd1318, %fd1273;
	add.f64 	%fd1277, %fd1323, %fd1324;
	mul.rn.f64 	%fd1325, %fd1273, %fd1310;
	neg.f64 	%fd1267, %fd1325;
	// inline asm
	fma.rn.f64 	%fd1264, %fd1273, %fd1310, %fd1267;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1268, %fd1277, %fd1306, %fd1264;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1272, %fd1273, %fd1306, %fd1268;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1276, %fd1277, %fd1310, %fd1272;
	// inline asm
	add.f64 	%fd1289, %fd1325, %fd1276;
	sub.f64 	%fd1326, %fd1325, %fd1289;
	add.f64 	%fd1293, %fd1276, %fd1326;
	mul.rn.f64 	%fd1327, %fd1289, %fd1310;
	neg.f64 	%fd1283, %fd1327;
	// inline asm
	fma.rn.f64 	%fd1280, %fd1289, %fd1310, %fd1283;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1284, %fd1293, %fd1306, %fd1280;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1288, %fd1289, %fd1306, %fd1284;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1292, %fd1293, %fd1310, %fd1288;
	// inline asm
	add.f64 	%fd1305, %fd1327, %fd1292;
	sub.f64 	%fd1328, %fd1327, %fd1305;
	add.f64 	%fd1309, %fd1292, %fd1328;
	mul.rn.f64 	%fd1329, %fd1305, %fd1310;
	neg.f64 	%fd1299, %fd1329;
	// inline asm
	fma.rn.f64 	%fd1296, %fd1305, %fd1310, %fd1299;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1300, %fd1309, %fd1306, %fd1296;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1304, %fd1305, %fd1306, %fd1300;
	// inline asm
	// inline asm
	fma.rn.f64 	%fd1308, %fd1309, %fd1310, %fd1304;
	// inline asm
	add.f64 	%fd1330, %fd1329, %fd1308;
	sub.f64 	%fd1331, %fd1329, %fd1330;
	add.f64 	%fd1332, %fd1308, %fd1331;
	add.f64 	%fd1333, %fd1310, %fd1330;
	sub.f64 	%fd1334, %fd1310, %fd1333;
	add.f64 	%fd1335, %fd1330, %fd1334;
	add.f64 	%fd1336, %fd1332, %fd1335;
	add.f64 	%fd1337, %fd1306, %fd1336;
	add.f64 	%fd1338, %fd1333, %fd1337;
	sub.f64 	%fd1339, %fd1333, %fd1338;
	add.f64 	%fd1340, %fd1337, %fd1339;
	cvt.rn.f64.s32	%fd1341, %r271;
	mov.f64 	%fd1342, 0d3FE62E42FEFA3000;
	mul.rn.f64 	%fd1343, %fd1341, %fd1342;
	mov.f64 	%fd1344, 0d3D53DE6AF278ECE6;
	mul.rn.f64 	%fd1345, %fd1341, %fd1344;
	add.f64 	%fd218, %fd1343, %fd1338;
	sub.f64 	%fd1346, %fd1343, %fd218;
	add.f64 	%fd1347, %fd1338, %fd1346;
	add.f64 	%fd1348, %fd1340, %fd1347;
	add.f64 	%fd219, %fd1345, %fd1348;
	setp.leu.f64	%p224, %fd213, 0d7F0D2A1BE4048F90;
	@%p224 bra 	BB0_202;

	mov.f64 	%fd1349, 0d3F20000000000000;
	mul.rn.f64 	%fd211, %fd211, %fd1349;

BB0_202:
	add.f64 	%fd1351, %fd218, %fd219;
	mul.rn.f64 	%fd1358, %fd1351, %fd211;
	neg.f64 	%fd1353, %fd1358;
	// inline asm
	fma.rn.f64 	%fd1350, %fd1351, %fd211, %fd1353;
	// inline asm
	sub.f64 	%fd1359, %fd218, %fd1351;
	add.f64 	%fd1355, %fd219, %fd1359;
	// inline asm
	fma.rn.f64 	%fd1354, %fd1355, %fd211, %fd1350;
	// inline asm
	add.f64 	%fd222, %fd1358, %fd1354;
	sub.f64 	%fd1360, %fd1358, %fd222;
	add.f64 	%fd223, %fd1354, %fd1360;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r101}, %fd222;
	}
	mov.b32 	 %f7, %r101;
	abs.f32 	%f8, %f7;
	setp.lt.f32	%p225, %f8, 0f40874911;
	@%p225 bra 	BB0_204;
	bra.uni 	BB0_203;

BB0_204:
	mov.f64 	%fd1364, 0d3FF71547652B82FE;
	mul.rn.f64 	%fd1365, %fd222, %fd1364;
	mov.f64 	%fd1366, 0d4338000000000000;
	add.rn.f64 	%fd1367, %fd1365, %fd1366;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r102, %temp}, %fd1367;
	}
	mov.f64 	%fd1368, 0dC338000000000000;
	add.rn.f64 	%fd1369, %fd1367, %fd1368;
	mov.f64 	%fd1370, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd1371, %fd1369, %fd1370, %fd222;
	mov.f64 	%fd1372, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd1373, %fd1369, %fd1372, %fd1371;
	mov.f64 	%fd1374, 0d3E928AF3FCA213EA;
	mov.f64 	%fd1375, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd1376, %fd1375, %fd1373, %fd1374;
	mov.f64 	%fd1377, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd1378, %fd1376, %fd1373, %fd1377;
	mov.f64 	%fd1379, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd1380, %fd1378, %fd1373, %fd1379;
	mov.f64 	%fd1381, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd1382, %fd1380, %fd1373, %fd1381;
	mov.f64 	%fd1383, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd1384, %fd1382, %fd1373, %fd1383;
	mov.f64 	%fd1385, 0d3F81111111122322;
	fma.rn.f64 	%fd1386, %fd1384, %fd1373, %fd1385;
	mov.f64 	%fd1387, 0d3FA55555555502A1;
	fma.rn.f64 	%fd1388, %fd1386, %fd1373, %fd1387;
	mov.f64 	%fd1389, 0d3FC5555555555511;
	fma.rn.f64 	%fd1390, %fd1388, %fd1373, %fd1389;
	mov.f64 	%fd1391, 0d3FE000000000000B;
	fma.rn.f64 	%fd1392, %fd1390, %fd1373, %fd1391;
	mov.f64 	%fd1393, 0d3FF0000000000000;
	fma.rn.f64 	%fd1394, %fd1392, %fd1373, %fd1393;
	fma.rn.f64 	%fd1570, %fd1394, %fd1373, %fd1393;
	abs.s32 	%r220, %r102;
	setp.lt.s32	%p228, %r220, 1023;
	@%p228 bra 	BB0_206;
	bra.uni 	BB0_205;

BB0_206:
	shl.b32 	%r226, %r102, 20;
	add.s32 	%r272, %r226, 1072693248;
	bra.uni 	BB0_207;

BB0_213:
	abs.f64 	%fd1485, %fd187;
	neg.f64 	%fd1574, %fd1485;

BB0_215:
	setp.neu.f64	%p234, %fd214, 0d3FF0000000000000;
	@%p234 bra 	BB0_224;

	mov.b64 	 %rd55, %fd1574;
	xor.b64  	%rd56, %rd55, -9223372036854775808;
	mov.b64 	 %fd1574, %rd56;
	bra.uni 	BB0_224;

BB0_203:
	setp.lt.s32	%p226, %r101, 0;
	selp.f64	%fd1361, 0d0000000000000000, 0d7FF0000000000000, %p226;
	abs.f64 	%fd1362, %fd222;
	setp.gtu.f64	%p227, %fd1362, 0d7FF0000000000000;
	add.f64 	%fd1363, %fd222, %fd222;
	selp.f64	%fd1574, %fd1363, %fd1361, %p227;
	bra.uni 	BB0_208;

BB0_205:
	add.s32 	%r221, %r102, 2046;
	shl.b32 	%r222, %r221, 19;
	and.b32  	%r223, %r222, -1048576;
	shl.b32 	%r224, %r221, 20;
	sub.s32 	%r272, %r224, %r223;
	mov.u32 	%r225, 0;
	mov.b64 	%fd1395, {%r225, %r223};
	mul.f64 	%fd1570, %fd1570, %fd1395;

BB0_207:
	mov.u32 	%r227, 0;
	mov.b64 	%fd1396, {%r227, %r272};
	mul.f64 	%fd1574, %fd1570, %fd1396;

BB0_208:
	abs.f64 	%fd1397, %fd1574;
	setp.eq.f64	%p229, %fd1397, 0d7FF0000000000000;
	@%p229 bra 	BB0_210;

	// inline asm
	fma.rn.f64 	%fd1574, %fd1574, %fd223, %fd1574;
	// inline asm

BB0_210:
	setp.neu.f64	%p230, %fd214, 0d3FF0000000000000;
	or.pred  	%p232, %p220, %p230;
	@%p232 bra 	BB0_224;

	mov.b64 	 %rd53, %fd1574;
	xor.b64  	%rd54, %rd53, -9223372036854775808;
	mov.b64 	 %fd1574, %rd54;

BB0_224:
	mul.rn.f64 	%fd1575, %fd1567, %fd1574;

BB0_225:
	add.f64 	%fd1561, %fd1561, %fd1575;

BB0_226:
	mov.f64 	%fd1577, 0d7FF8000000000214;
	setp.le.f64	%p241, %fd1544, 0d3FF0000000000000;
	@%p241 bra 	BB0_228;

	add.f64 	%fd1405, %fd1544, 0dBFF0000000000000;
	div.rn.f64 	%fd1577, %fd1561, %fd1405;

BB0_228:
	setp.gt.f64	%p242, %fd106, 0d0000000000000000;
	setp.lt.f64	%p243, %fd1577, 0d0000000000000000;
	and.pred  	%p244, %p243, %p242;
	@%p244 bra 	BB0_230;

	setp.lt.f64	%p245, %fd106, 0d0000000000000000;
	setp.gt.f64	%p246, %fd1577, 0d0000000000000000;
	and.pred  	%p247, %p245, %p246;
	@!%p247 bra 	BB0_239;
	bra.uni 	BB0_230;

BB0_230:
	neg.f64 	%fd250, %fd106;
	setp.eq.f64	%p248, %fd1577, %fd250;
	mov.f64 	%fd1578, 0d0000000000000000;
	@%p248 bra 	BB0_240;

	setp.eq.f64	%p249, %fd1577, 0d0000000000000000;
	setp.eq.f64	%p250, %fd106, 0d8000000000000000;
	or.pred  	%p251, %p249, %p250;
	@%p251 bra 	BB0_239;

	add.f64 	%fd1407, %fd106, %fd1577;
	abs.f64 	%fd251, %fd1407;
	abs.f64 	%fd1408, %fd251;
	setp.geu.f64	%p252, %fd1408, 0d7FF0000000000000;
	@%p252 bra 	BB0_239;

	abs.f64 	%fd252, %fd1577;
	mul.f64 	%fd1409, %fd252, 0d3D30000000000000;
	setp.gt.f64	%p253, %fd251, %fd1409;
	@%p253 bra 	BB0_239;

	abs.f64 	%fd253, %fd250;
	mul.f64 	%fd1410, %fd253, 0d3D30000000000000;
	setp.gt.f64	%p254, %fd251, %fd1410;
	@%p254 bra 	BB0_239;

	setp.gtu.f64	%p255, %fd251, 0d433FFFFFFFFFFFFF;
	@%p255 bra 	BB0_279;

	cvt.rzi.s64.f64	%rd57, %fd251;
	setp.gt.s64	%p256, %rd57, 9007199254740991;
	cvt.rn.f64.s64	%fd1411, %rd57;
	setp.ne.f64	%p257, %fd1411, %fd251;
	or.pred  	%p258, %p256, %p257;
	setp.gtu.f64	%p259, %fd252, 0d433FFFFFFFFFFFFF;
	or.pred  	%p260, %p258, %p259;
	@%p260 bra 	BB0_279;

	cvt.rzi.s64.f64	%rd58, %fd252;
	setp.gt.s64	%p261, %rd58, 9007199254740991;
	cvt.rn.f64.s64	%fd1412, %rd58;
	setp.ne.f64	%p262, %fd1412, %fd252;
	or.pred  	%p263, %p261, %p262;
	setp.gtu.f64	%p264, %fd253, 0d433FFFFFFFFFFFFF;
	or.pred  	%p265, %p263, %p264;
	@%p265 bra 	BB0_279;
	bra.uni 	BB0_238;

BB0_279:
	mul.f64 	%fd1418, %fd252, 0d3CF0000000000000;
	setp.geu.f64	%p273, %fd251, %fd1418;
	mul.f64 	%fd1419, %fd253, 0d3CF0000000000000;
	setp.geu.f64	%p274, %fd251, %fd1419;
	or.pred  	%p275, %p273, %p274;
	@!%p275 bra 	BB0_240;
	bra.uni 	BB0_239;

BB0_238:
	cvt.rzi.s64.f64	%rd59, %fd253;
	setp.lt.s64	%p266, %rd59, 9007199254740992;
	cvt.rn.f64.s64	%fd1414, %rd59;
	setp.equ.f64	%p267, %fd1414, %fd253;
	and.pred  	%p268, %p266, %p267;
	mul.f64 	%fd1415, %fd252, 0d3CF0000000000000;
	setp.geu.f64	%p269, %fd251, %fd1415;
	or.pred  	%p270, %p268, %p269;
	mul.f64 	%fd1416, %fd253, 0d3CF0000000000000;
	setp.geu.f64	%p271, %fd251, %fd1416;
	or.pred  	%p272, %p271, %p270;
	@%p272 bra 	BB0_239;
	bra.uni 	BB0_240;

BB0_239:
	add.f64 	%fd1578, %fd106, %fd1577;

BB0_240:
	setp.lt.f64	%p276, %fd1538, 0d0000000000000000;
	setp.lt.f64	%p277, %fd1578, 0d0000000000000000;
	and.pred  	%p278, %p277, %p276;
	@%p278 bra 	BB0_242;

	setp.gt.f64	%p279, %fd1578, 0d0000000000000000;
	setp.gt.f64	%p280, %fd1538, 0d0000000000000000;
	and.pred  	%p281, %p279, %p280;
	@!%p281 bra 	BB0_251;
	bra.uni 	BB0_242;

BB0_242:
	setp.eq.f64	%p282, %fd1578, %fd1538;
	mov.f64 	%fd1579, 0d0000000000000000;
	@%p282 bra 	BB0_252;

	setp.eq.f64	%p283, %fd1578, 0d0000000000000000;
	setp.eq.f64	%p284, %fd1538, 0d0000000000000000;
	or.pred  	%p285, %p283, %p284;
	@%p285 bra 	BB0_251;

	sub.f64 	%fd1421, %fd1578, %fd1538;
	abs.f64 	%fd256, %fd1421;
	abs.f64 	%fd1422, %fd256;
	setp.geu.f64	%p286, %fd1422, 0d7FF0000000000000;
	@%p286 bra 	BB0_251;

	abs.f64 	%fd257, %fd1578;
	mul.f64 	%fd1423, %fd257, 0d3D30000000000000;
	setp.gt.f64	%p287, %fd256, %fd1423;
	@%p287 bra 	BB0_251;

	abs.f64 	%fd258, %fd1538;
	mul.f64 	%fd1424, %fd258, 0d3D30000000000000;
	setp.gt.f64	%p288, %fd256, %fd1424;
	@%p288 bra 	BB0_251;

	setp.gtu.f64	%p289, %fd256, 0d433FFFFFFFFFFFFF;
	@%p289 bra 	BB0_280;

	cvt.rzi.s64.f64	%rd60, %fd256;
	setp.gt.s64	%p290, %rd60, 9007199254740991;
	cvt.rn.f64.s64	%fd1425, %rd60;
	setp.ne.f64	%p291, %fd1425, %fd256;
	or.pred  	%p292, %p290, %p291;
	setp.gtu.f64	%p293, %fd257, 0d433FFFFFFFFFFFFF;
	or.pred  	%p294, %p292, %p293;
	@%p294 bra 	BB0_280;

	cvt.rzi.s64.f64	%rd61, %fd257;
	setp.gt.s64	%p295, %rd61, 9007199254740991;
	cvt.rn.f64.s64	%fd1426, %rd61;
	setp.ne.f64	%p296, %fd1426, %fd257;
	or.pred  	%p297, %p295, %p296;
	setp.gtu.f64	%p298, %fd258, 0d433FFFFFFFFFFFFF;
	or.pred  	%p299, %p297, %p298;
	@%p299 bra 	BB0_280;
	bra.uni 	BB0_250;

BB0_280:
	mul.f64 	%fd1432, %fd257, 0d3CF0000000000000;
	setp.geu.f64	%p307, %fd256, %fd1432;
	mul.f64 	%fd1433, %fd258, 0d3CF0000000000000;
	setp.geu.f64	%p308, %fd256, %fd1433;
	or.pred  	%p309, %p307, %p308;
	@!%p309 bra 	BB0_252;
	bra.uni 	BB0_251;

BB0_250:
	cvt.rzi.s64.f64	%rd62, %fd258;
	setp.lt.s64	%p300, %rd62, 9007199254740992;
	cvt.rn.f64.s64	%fd1428, %rd62;
	setp.equ.f64	%p301, %fd1428, %fd258;
	and.pred  	%p302, %p300, %p301;
	mul.f64 	%fd1429, %fd257, 0d3CF0000000000000;
	setp.geu.f64	%p303, %fd256, %fd1429;
	or.pred  	%p304, %p302, %p303;
	mul.f64 	%fd1430, %fd258, 0d3CF0000000000000;
	setp.geu.f64	%p305, %fd256, %fd1430;
	or.pred  	%p306, %p305, %p304;
	@%p306 bra 	BB0_251;
	bra.uni 	BB0_252;

BB0_251:
	sub.f64 	%fd1579, %fd1578, %fd1538;

BB0_252:
	setp.gt.f64	%p310, %fd62, 0d0000000000000000;
	setp.lt.f64	%p311, %fd1579, 0d0000000000000000;
	and.pred  	%p312, %p311, %p310;
	@%p312 bra 	BB0_254;

	setp.lt.f64	%p313, %fd62, 0d0000000000000000;
	setp.gt.f64	%p314, %fd1579, 0d0000000000000000;
	and.pred  	%p315, %p313, %p314;
	@!%p315 bra 	BB0_263;
	bra.uni 	BB0_254;

BB0_254:
	neg.f64 	%fd261, %fd62;
	setp.eq.f64	%p316, %fd1579, %fd261;
	mov.f64 	%fd1580, 0d0000000000000000;
	@%p316 bra 	BB0_264;

	setp.eq.f64	%p317, %fd1579, 0d0000000000000000;
	setp.eq.f64	%p318, %fd62, 0d8000000000000000;
	or.pred  	%p319, %p317, %p318;
	@%p319 bra 	BB0_263;

	add.f64 	%fd1435, %fd62, %fd1579;
	abs.f64 	%fd262, %fd1435;
	abs.f64 	%fd1436, %fd262;
	setp.geu.f64	%p320, %fd1436, 0d7FF0000000000000;
	@%p320 bra 	BB0_263;

	abs.f64 	%fd263, %fd1579;
	mul.f64 	%fd1437, %fd263, 0d3D30000000000000;
	setp.gt.f64	%p321, %fd262, %fd1437;
	@%p321 bra 	BB0_263;

	abs.f64 	%fd264, %fd261;
	mul.f64 	%fd1438, %fd264, 0d3D30000000000000;
	setp.gt.f64	%p322, %fd262, %fd1438;
	@%p322 bra 	BB0_263;

	setp.gtu.f64	%p323, %fd262, 0d433FFFFFFFFFFFFF;
	@%p323 bra 	BB0_281;

	cvt.rzi.s64.f64	%rd63, %fd262;
	setp.gt.s64	%p324, %rd63, 9007199254740991;
	cvt.rn.f64.s64	%fd1439, %rd63;
	setp.ne.f64	%p325, %fd1439, %fd262;
	or.pred  	%p326, %p324, %p325;
	setp.gtu.f64	%p327, %fd263, 0d433FFFFFFFFFFFFF;
	or.pred  	%p328, %p326, %p327;
	@%p328 bra 	BB0_281;

	cvt.rzi.s64.f64	%rd64, %fd263;
	setp.gt.s64	%p329, %rd64, 9007199254740991;
	cvt.rn.f64.s64	%fd1440, %rd64;
	setp.ne.f64	%p330, %fd1440, %fd263;
	or.pred  	%p331, %p329, %p330;
	setp.gtu.f64	%p332, %fd264, 0d433FFFFFFFFFFFFF;
	or.pred  	%p333, %p331, %p332;
	@%p333 bra 	BB0_281;
	bra.uni 	BB0_262;

BB0_281:
	mul.f64 	%fd1446, %fd263, 0d3CF0000000000000;
	setp.geu.f64	%p341, %fd262, %fd1446;
	mul.f64 	%fd1447, %fd264, 0d3CF0000000000000;
	setp.geu.f64	%p342, %fd262, %fd1447;
	or.pred  	%p343, %p341, %p342;
	@!%p343 bra 	BB0_264;
	bra.uni 	BB0_263;

BB0_262:
	cvt.rzi.s64.f64	%rd65, %fd264;
	setp.lt.s64	%p334, %rd65, 9007199254740992;
	cvt.rn.f64.s64	%fd1442, %rd65;
	setp.equ.f64	%p335, %fd1442, %fd264;
	and.pred  	%p336, %p334, %p335;
	mul.f64 	%fd1443, %fd263, 0d3CF0000000000000;
	setp.geu.f64	%p337, %fd262, %fd1443;
	or.pred  	%p338, %p336, %p337;
	mul.f64 	%fd1444, %fd264, 0d3CF0000000000000;
	setp.geu.f64	%p339, %fd262, %fd1444;
	or.pred  	%p340, %p339, %p338;
	@%p340 bra 	BB0_263;
	bra.uni 	BB0_264;

BB0_263:
	add.f64 	%fd1580, %fd62, %fd1579;

BB0_264:
	setp.gt.f64	%p344, %fd29, 0d0000000000000000;
	setp.lt.f64	%p345, %fd1580, 0d0000000000000000;
	and.pred  	%p346, %p345, %p344;
	@%p346 bra 	BB0_266;

	setp.lt.f64	%p347, %fd29, 0d0000000000000000;
	setp.gt.f64	%p348, %fd1580, 0d0000000000000000;
	and.pred  	%p349, %p347, %p348;
	@!%p349 bra 	BB0_275;
	bra.uni 	BB0_266;

BB0_266:
	neg.f64 	%fd267, %fd29;
	setp.eq.f64	%p350, %fd1580, %fd267;
	mov.f64 	%fd1581, 0d0000000000000000;
	@%p350 bra 	BB0_276;

	setp.eq.f64	%p351, %fd1580, 0d0000000000000000;
	setp.eq.f64	%p352, %fd29, 0d8000000000000000;
	or.pred  	%p353, %p351, %p352;
	@%p353 bra 	BB0_275;

	add.f64 	%fd1449, %fd29, %fd1580;
	abs.f64 	%fd268, %fd1449;
	abs.f64 	%fd1450, %fd268;
	setp.geu.f64	%p354, %fd1450, 0d7FF0000000000000;
	@%p354 bra 	BB0_275;

	abs.f64 	%fd269, %fd1580;
	mul.f64 	%fd1451, %fd269, 0d3D30000000000000;
	setp.gt.f64	%p355, %fd268, %fd1451;
	@%p355 bra 	BB0_275;

	abs.f64 	%fd270, %fd267;
	mul.f64 	%fd1452, %fd270, 0d3D30000000000000;
	setp.gt.f64	%p356, %fd268, %fd1452;
	@%p356 bra 	BB0_275;

	setp.gtu.f64	%p357, %fd268, 0d433FFFFFFFFFFFFF;
	@%p357 bra 	BB0_282;

	cvt.rzi.s64.f64	%rd66, %fd268;
	setp.gt.s64	%p358, %rd66, 9007199254740991;
	cvt.rn.f64.s64	%fd1453, %rd66;
	setp.ne.f64	%p359, %fd1453, %fd268;
	or.pred  	%p360, %p358, %p359;
	setp.gtu.f64	%p361, %fd269, 0d433FFFFFFFFFFFFF;
	or.pred  	%p362, %p360, %p361;
	@%p362 bra 	BB0_282;

	cvt.rzi.s64.f64	%rd67, %fd269;
	setp.gt.s64	%p363, %rd67, 9007199254740991;
	cvt.rn.f64.s64	%fd1454, %rd67;
	setp.ne.f64	%p364, %fd1454, %fd269;
	or.pred  	%p365, %p363, %p364;
	setp.gtu.f64	%p366, %fd270, 0d433FFFFFFFFFFFFF;
	or.pred  	%p367, %p365, %p366;
	@%p367 bra 	BB0_282;
	bra.uni 	BB0_274;

BB0_282:
	mul.f64 	%fd1460, %fd269, 0d3CF0000000000000;
	setp.geu.f64	%p375, %fd268, %fd1460;
	mul.f64 	%fd1461, %fd270, 0d3CF0000000000000;
	setp.geu.f64	%p376, %fd268, %fd1461;
	or.pred  	%p377, %p375, %p376;
	@!%p377 bra 	BB0_276;
	bra.uni 	BB0_275;

BB0_274:
	cvt.rzi.s64.f64	%rd68, %fd270;
	setp.lt.s64	%p368, %rd68, 9007199254740992;
	cvt.rn.f64.s64	%fd1456, %rd68;
	setp.equ.f64	%p369, %fd1456, %fd270;
	and.pred  	%p370, %p368, %p369;
	mul.f64 	%fd1457, %fd269, 0d3CF0000000000000;
	setp.geu.f64	%p371, %fd268, %fd1457;
	or.pred  	%p372, %p370, %p371;
	mul.f64 	%fd1458, %fd270, 0d3CF0000000000000;
	setp.geu.f64	%p373, %fd268, %fd1458;
	or.pred  	%p374, %p373, %p372;
	@%p374 bra 	BB0_275;
	bra.uni 	BB0_276;

BB0_275:
	add.f64 	%fd1581, %fd29, %fd1580;

BB0_276:
	mov.b32	%r234, %envreg3;
	mov.u32 	%r233, %ntid.x;
	mov.u32 	%r232, %ctaid.x;
	mov.u32 	%r231, %tid.x;
	mad.lo.s32 	%r230, %r232, %r233, %r234;
	add.s32 	%r229, %r230, %r231;
	mul.wide.s32 	%rd72, %r229, 8;
	ld.param.u64 	%rd71, [DynamicKernel_nop_fsum_fsum_fsub_fsum_Var_OpNormsdist_Covar_OpPearson_Slope_param_0];
	add.s64 	%rd70, %rd71, %rd72;
	st.global.f64 	[%rd70], %fd1581;
	ret;
}


  